{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cohere-multilingual-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "âœ… SemChunk chunker hazÄ±r (Token boyutu: 384)\n",
      "âœ… Cohere client hazÄ±r (embed-multilingual-v3.0)\n",
      "âœ… Qdrant client hazÄ±r (http://localhost:6333)\n",
      "\n",
      "==================================================\n",
      "ğŸ›ï¸ YARGITAY SEMANTÄ°K CHUNK SÄ°STEMÄ°\n",
      "==================================================\n",
      "1. Tam pipeline Ã§alÄ±ÅŸtÄ±r (CSV â†’ Semantic Chunks â†’ Qdrant)\n",
      "2. Ä°nteraktif arama yap\n",
      "3. Koleksiyon bilgilerini gÃ¶ster\n",
      "4. Ã‡Ä±kÄ±ÅŸ\n",
      "ğŸš€ YargÄ±tay Semantic Pipeline BaÅŸlÄ±yor\n",
      "==================================================\n",
      "âŒ Cohere baÄŸlantÄ± hatasÄ±: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '9e4699f7af22b34b5a38e05ab96b6167', 'x-trial-endpoint-call-limit': '100', 'x-trial-endpoint-call-remaining': '99', 'date': 'Tue, 09 Sep 2025 11:03:45 GMT', 'content-length': '373', 'x-envoy-upstream-service-time': '12', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '7ff541e5-1f43-4ef0-935a-c11034a2b057', 'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
      "âŒ Pipeline hatasÄ±!\n",
      "\n",
      "==================================================\n",
      "ğŸ›ï¸ YARGITAY SEMANTÄ°K CHUNK SÄ°STEMÄ°\n",
      "==================================================\n",
      "1. Tam pipeline Ã§alÄ±ÅŸtÄ±r (CSV â†’ Semantic Chunks â†’ Qdrant)\n",
      "2. Ä°nteraktif arama yap\n",
      "3. Koleksiyon bilgilerini gÃ¶ster\n",
      "4. Ã‡Ä±kÄ±ÅŸ\n",
      "ğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!\n"
     ]
    }
   ],
   "source": [
    "# SemChunk + Cohere Multilingual + Qdrant Entegrasyon\n",
    "# YargÄ±tay KararlarÄ± iÃ§in Semantic Chunking Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import semchunk\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "import cohere\n",
    "import numpy as np\n",
    "import uuid\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(load_dotenv(\"/home/yapayzeka/ahsen_bulbul/qdrant/.env\"))\n",
    "\n",
    "cohere_api_key=os.getenv(\"COHERE_API_KEY\")\n",
    "# KonfigÃ¼rasyon\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Cohere ayarlarÄ±\n",
    "    COHERE_API_KEY: str = cohere_api_key  # Cohere API anahtarÄ±nÄ±z\n",
    "    COHERE_MODEL: str = \"embed-multilingual-v3.0\"  # Cohere multilingual model\n",
    "    \n",
    "    # SemChunk ayarlarÄ±\n",
    "    TOKEN_SIZE: int = 384  # Chunk boyutu (token)\n",
    "    ENCODING_NAME: str = \"cl100k_base\"  # Tiktoken encoding\n",
    "    \n",
    "    # Qdrant ayarlarÄ±\n",
    "    QDRANT_URL: str = \"http://localhost:6333\"  # Lokal Qdrant\n",
    "    COLLECTION_NAME: str = \"yargitay_semantic_chunks\"\n",
    "    DIMENSION: int = 1024  # Cohere multilingual embedding boyutu\n",
    "    \n",
    "    # Dosya ayarlarÄ±\n",
    "    CSV_FILE: str = \"/home/yapayzeka/ahsen_bulbul/data/10data.csv\"\n",
    "    BATCH_SIZE: int = 10\n",
    "\n",
    "class YargitaySemanticProcessor:\n",
    "    \"\"\"YargÄ±tay kararlarÄ± iÃ§in semantic chunking ve vector search\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        \n",
    "        # SemChunk chunker oluÅŸtur\n",
    "        self.encoding = tiktoken.get_encoding(config.ENCODING_NAME)\n",
    "        self.chunker = semchunk.chunkerify(self.encoding, config.TOKEN_SIZE)\n",
    "        \n",
    "        # Cohere client oluÅŸtur\n",
    "        self.cohere_client = cohere.Client(config.COHERE_API_KEY)\n",
    "        \n",
    "        # Qdrant client oluÅŸtur\n",
    "        self.qdrant_client = QdrantClient(url=config.QDRANT_URL)\n",
    "        \n",
    "        print(f\"âœ… SemChunk chunker hazÄ±r (Token boyutu: {config.TOKEN_SIZE})\")\n",
    "        print(f\"âœ… Cohere client hazÄ±r ({config.COHERE_MODEL})\")\n",
    "        print(f\"âœ… Qdrant client hazÄ±r ({config.QDRANT_URL})\")\n",
    "    \n",
    "    def test_cohere_connection(self):\n",
    "        \"\"\"Cohere baÄŸlantÄ±sÄ±nÄ± test et\"\"\"\n",
    "        try:\n",
    "            test_response = self.cohere_client.embed(\n",
    "                texts=[\"Bu bir test metnidir\"],\n",
    "                model=self.config.COHERE_MODEL,\n",
    "                input_type=\"search_document\"\n",
    "            )\n",
    "            embedding_dim = len(test_response.embeddings[0])\n",
    "            print(f\"âœ… Cohere test baÅŸarÄ±lÄ± - Embedding boyutu: {embedding_dim}\")\n",
    "            return embedding_dim\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Cohere baÄŸlantÄ± hatasÄ±: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def create_qdrant_collection(self, recreate: bool = False):\n",
    "        \"\"\"Qdrant koleksiyonu oluÅŸtur\"\"\"\n",
    "        collection_name = self.config.COLLECTION_NAME\n",
    "        \n",
    "        # Koleksiyon varsa ve recreate True ise sil\n",
    "        if recreate:\n",
    "            try:\n",
    "                self.qdrant_client.delete_collection(collection_name)\n",
    "                print(f\"ğŸ—‘ï¸ Eski koleksiyon silindi: {collection_name}\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Koleksiyon yoksa oluÅŸtur\n",
    "        try:\n",
    "            collections = self.qdrant_client.get_collections().collections\n",
    "            collection_names = [c.name for c in collections]\n",
    "            \n",
    "            if collection_name not in collection_names:\n",
    "                self.qdrant_client.create_collection(\n",
    "                    collection_name=collection_name,\n",
    "                    vectors_config=VectorParams(\n",
    "                        size=self.config.DIMENSION,\n",
    "                        distance=Distance.COSINE\n",
    "                    )\n",
    "                )\n",
    "                print(f\"âœ… Koleksiyon oluÅŸturuldu: {collection_name}\")\n",
    "            else:\n",
    "                print(f\"â„¹ï¸ Koleksiyon zaten var: {collection_name}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Koleksiyon oluÅŸturma hatasÄ±: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def semantic_chunk_text(self, text: str, metadata: dict = None) -> List[Dict]:\n",
    "        \"\"\"Metni semantic olarak chunk'lara bÃ¶l\"\"\"\n",
    "        if not text or text.strip() == \"\":\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # SemChunk ile metni bÃ¶l\n",
    "            chunks = self.chunker(text)\n",
    "            \n",
    "            result_chunks = []\n",
    "            for i, chunk_text in enumerate(chunks):\n",
    "                if chunk_text.strip():  # BoÅŸ chunk'larÄ± atla\n",
    "                    chunk_data = {\n",
    "                        'chunk_id': i,\n",
    "                        'text': chunk_text.strip(),\n",
    "                        'token_count': len(self.encoding.encode(chunk_text)),\n",
    "                        'char_count': len(chunk_text),\n",
    "                    }\n",
    "                    \n",
    "                    # Metadata ekle\n",
    "                    if metadata:\n",
    "                        chunk_data.update(metadata)\n",
    "                    \n",
    "                    result_chunks.append(chunk_data)\n",
    "            \n",
    "            return result_chunks\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Chunking hatasÄ±: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def create_embeddings(self, texts: List[str], batch_size: int = 10) -> List[List[float]]:\n",
    "        \"\"\"Metinleri Cohere ile embedding'e Ã§evir\"\"\"\n",
    "        all_embeddings = []\n",
    "        \n",
    "        # Cohere API limitleri iÃ§in batch processing\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            \n",
    "            try:\n",
    "                response = self.cohere_client.embed(\n",
    "                    texts=batch_texts,\n",
    "                    model=self.config.COHERE_MODEL,\n",
    "                    input_type=\"search_document\"  # Dokuman indexleme iÃ§in\n",
    "                )\n",
    "                \n",
    "                batch_embeddings = response.embeddings\n",
    "                all_embeddings.extend(batch_embeddings)\n",
    "                \n",
    "                print(f\"  ğŸ“Š Embedding oluÅŸturuldu: {i+len(batch_texts)}/{len(texts)}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Embedding hatasÄ± (batch {i//batch_size + 1}): {e}\")\n",
    "                # Hata durumunda boÅŸ embedding ekle\n",
    "                all_embeddings.extend([[0.0] * self.config.EMBEDDING_DIM] * len(batch_texts))\n",
    "        \n",
    "        return all_embeddings\n",
    "    \n",
    "    def process_csv_file(self, csv_path: str) -> List[Dict]:\n",
    "        \"\"\"CSV dosyasÄ±nÄ± iÅŸle ve chunk'larÄ± oluÅŸtur\"\"\"\n",
    "        print(f\"ğŸ“„ CSV dosyasÄ± okunuyor: {csv_path}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            print(f\"ğŸ“Š {len(df)} satÄ±r veri yÃ¼klendi\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ CSV okuma hatasÄ±: {e}\")\n",
    "            return []\n",
    "        \n",
    "        # Gerekli sÃ¼tunlarÄ± kontrol et\n",
    "        required_columns = ['rawText']  # Ana metin sÃ¼tunu\n",
    "        optional_columns = ['esasNo', 'kararNo', 'location', 'extractedDates']\n",
    "        \n",
    "        if 'rawText' not in df.columns:\n",
    "            print(f\"âŒ 'rawText' sÃ¼tunu bulunamadÄ±. Mevcut sÃ¼tunlar: {df.columns.tolist()}\")\n",
    "            return []\n",
    "        \n",
    "        all_chunks = []\n",
    "        \n",
    "        print(\"ğŸ”„ Semantic chunking baÅŸlÄ±yor...\")\n",
    "        for idx, row in df.iterrows():\n",
    "            # Ana metni al\n",
    "            text = row.get('rawText', '') or row.get('text', '')\n",
    "            \n",
    "            if not text or pd.isna(text):\n",
    "                continue\n",
    "            \n",
    "            # Metadata hazÄ±rla\n",
    "            metadata = {\n",
    "                'original_index': idx,\n",
    "                'esas_no': row.get('esasNo', ''),\n",
    "                'karar_no': row.get('kararNo', ''),\n",
    "                'daire': row.get('location', ''),\n",
    "                'tarih': row.get('extractedDates', '')\n",
    "                #'karar_turu': row.get('karar_turu', ''),\n",
    "            }\n",
    "            \n",
    "            # Semantic chunking yap\n",
    "            chunks = self.semantic_chunk_text(str(text), metadata)\n",
    "            all_chunks.extend(chunks)\n",
    "            \n",
    "            # Progress gÃ¶ster\n",
    "            if (idx + 1) % 100 == 0:\n",
    "                print(f\"  âœ… Ä°ÅŸlenen satÄ±r: {idx + 1}/{len(df)} (Toplam chunk: {len(all_chunks)})\")\n",
    "        \n",
    "        print(f\"ğŸ§© Toplam {len(all_chunks)} chunk oluÅŸturuldu\")\n",
    "        return all_chunks\n",
    "    \n",
    "    def upload_to_qdrant(self, chunks: List[Dict]):\n",
    "        \"\"\"Chunk'larÄ± Qdrant'a yÃ¼kle\"\"\"\n",
    "        if not chunks:\n",
    "            print(\"âŒ YÃ¼klenecek chunk yok\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸš€ {len(chunks)} chunk Qdrant'a yÃ¼kleniyor...\")\n",
    "        \n",
    "        # Metinleri topla\n",
    "        texts = [chunk['text'] for chunk in chunks]\n",
    "        \n",
    "        # Embedding'leri oluÅŸtur\n",
    "        print(\"ğŸ”® Embedding'ler oluÅŸturuluyor...\")\n",
    "        embeddings = self.create_embeddings(texts)\n",
    "        \n",
    "        if len(embeddings) != len(chunks):\n",
    "            print(f\"âŒ Embedding sayÄ±sÄ± uyumsuz: {len(embeddings)} vs {len(chunks)}\")\n",
    "            return\n",
    "        \n",
    "        # Qdrant point'leri hazÄ±rla\n",
    "        points = []\n",
    "        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "            point = PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector=embedding,\n",
    "                payload=chunk\n",
    "            )\n",
    "            points.append(point)\n",
    "        \n",
    "        # Batch halinde yÃ¼kle\n",
    "        batch_size = self.config.BATCH_SIZE\n",
    "        print(f\"ğŸ“¦ {batch_size} batch size ile yÃ¼kleniyor...\")\n",
    "        \n",
    "        for i in range(0, len(points), batch_size):\n",
    "            batch = points[i:i + batch_size]\n",
    "            \n",
    "            try:\n",
    "                self.qdrant_client.upsert(\n",
    "                    collection_name=self.config.COLLECTION_NAME,\n",
    "                    points=batch\n",
    "                )\n",
    "                print(f\"  âœ… Batch yÃ¼klendi: {min(i + batch_size, len(points))}/{len(points)}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Batch yÃ¼kleme hatasÄ±: {e}\")\n",
    "        \n",
    "        print(\"ğŸ‰ YÃ¼kleme tamamlandÄ±!\")\n",
    "    \n",
    "    def search_semantic(self, query: str, limit: int = 10, score_threshold: float = 0.7) -> List[Dict]:\n",
    "        \"\"\"Semantic arama yap\"\"\"\n",
    "        print(f\"ğŸ” Arama: '{query}'\")\n",
    "        \n",
    "        try:\n",
    "            # Query iÃ§in embedding oluÅŸtur\n",
    "            query_response = self.cohere_client.embed(\n",
    "                texts=[query],\n",
    "                model=self.config.COHERE_MODEL,\n",
    "                input_type=\"search_query\"  # Arama query'si iÃ§in\n",
    "            )\n",
    "            query_embedding = query_response.embeddings[0]\n",
    "            \n",
    "            # Qdrant'ta ara\n",
    "            search_results = self.qdrant_client.search(\n",
    "                collection_name=self.config.COLLECTION_NAME,\n",
    "                query_vector=query_embedding,\n",
    "                limit=limit,\n",
    "                score_threshold=score_threshold\n",
    "            )\n",
    "            \n",
    "            # SonuÃ§larÄ± formatla\n",
    "            results = []\n",
    "            for point in search_results:\n",
    "                results.append({\n",
    "                    'score': point.score,\n",
    "                    'payload': point.payload\n",
    "                })\n",
    "            \n",
    "            print(f\"ğŸ“Š {len(results)} sonuÃ§ bulundu\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Arama hatasÄ±: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_collection_info(self) -> dict:\n",
    "        \"\"\"Koleksiyon bilgilerini al\"\"\"\n",
    "        try:\n",
    "            info = self.qdrant_client.get_collection(self.config.COLLECTION_NAME)\n",
    "            return {\n",
    "                \"collection_name\": self.config.COLLECTION_NAME,\n",
    "                \"points_count\": info.points_count,\n",
    "                \"vectors_count\": info.vectors_count,\n",
    "                \"status\": info.status\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "# Ana Pipeline SÄ±nÄ±fÄ±\n",
    "class YargitayPipeline:\n",
    "    \"\"\"Ana pipeline sÄ±nÄ±fÄ±\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.processor = YargitaySemanticProcessor(config)\n",
    "        self.config = config\n",
    "    \n",
    "    def full_pipeline(self, csv_path: str = None):\n",
    "        \"\"\"Tam pipeline'Ä± Ã§alÄ±ÅŸtÄ±r\"\"\"\n",
    "        csv_path = csv_path or self.config.CSV_FILE\n",
    "        \n",
    "        print(\"ğŸš€ YargÄ±tay Semantic Pipeline BaÅŸlÄ±yor\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # 1. BaÄŸlantÄ±larÄ± test et\n",
    "        embedding_dim = self.processor.test_cohere_connection()\n",
    "        if not embedding_dim:\n",
    "            return False\n",
    "        \n",
    "        # 2. Koleksiyon oluÅŸtur\n",
    "        self.processor.create_qdrant_collection(recreate=True)\n",
    "        \n",
    "        # 3. CSV'yi iÅŸle\n",
    "        chunks = self.processor.process_csv_file(csv_path)\n",
    "        if not chunks:\n",
    "            print(\"âŒ Ä°ÅŸlenecek chunk bulunamadÄ±\")\n",
    "            return False\n",
    "        \n",
    "        # 4. Qdrant'a yÃ¼kle\n",
    "        self.processor.upload_to_qdrant(chunks)\n",
    "        \n",
    "        # 5. Bilgileri gÃ¶ster\n",
    "        info = self.processor.get_collection_info()\n",
    "        print(\"\\nğŸ“Š Koleksiyon Bilgileri:\")\n",
    "        print(json.dumps(info, indent=2, ensure_ascii=False))\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def interactive_search(self):\n",
    "        \"\"\"Ä°nteraktif arama arayÃ¼zÃ¼\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ğŸ›ï¸ YARGITAY SEMANTÄ°K ARAMA SÄ°STEMÄ°\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        while True:\n",
    "            query = input(\"\\nğŸ” Arama metni (Ã§Ä±kmak iÃ§in 'q'): \")\n",
    "            if query.lower() in ['q', 'quit', 'exit']:\n",
    "                print(\"ğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!\")\n",
    "                break\n",
    "            \n",
    "            if not query.strip():\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                limit = int(input(\"ğŸ“Š KaÃ§ sonuÃ§? (varsayÄ±lan 5): \") or \"5\")\n",
    "            except:\n",
    "                limit = 5\n",
    "            \n",
    "            # Arama yap\n",
    "            results = self.processor.search_semantic(query, limit=limit)\n",
    "            \n",
    "            if not results:\n",
    "                print(\"âŒ SonuÃ§ bulunamadÄ±\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nğŸ“‹ {len(results)} sonuÃ§ bulundu:\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            for i, result in enumerate(results, 1):\n",
    "                payload = result['payload']\n",
    "                print(f\"\\n{i}. ğŸ“„ Benzerlik Skoru: {result['score']:.3f}\")\n",
    "                print(f\"   âš–ï¸ Esas No: {payload.get('esas_no', 'N/A')}\")\n",
    "                print(f\"   ğŸ“‹ Karar No: {payload.get('karar_no', 'N/A')}\")\n",
    "                print(f\"   ğŸ›ï¸ Daire: {payload.get('daire', 'N/A')}\")\n",
    "                print(f\"   ğŸ“… Tarih: {payload.get('tarih', 'N/A')}\")\n",
    "                print(f\"   ğŸ”¤ Token: {payload.get('token_count', 'N/A')}\")\n",
    "                print(f\"   ğŸ“ Metin Ã–nizleme:\")\n",
    "                \n",
    "                text = payload.get('text', '')\n",
    "                preview = text[:300] + \"...\" if len(text) > 300 else text\n",
    "                print(f\"      {preview}\")\n",
    "                print(\"-\" * 60)\n",
    "\n",
    "# KullanÄ±m Ã¶rneÄŸi ve main fonksiyon\n",
    "def main():\n",
    "    \"\"\"Ana fonksiyon\"\"\"\n",
    "    \n",
    "    # KonfigÃ¼rasyon (buraya kendi bilgilerinizi yazÄ±n)\n",
    "    config = Config(\n",
    "        COHERE_API_KEY=str(cohere_api_key),  # Cohere API anahtarÄ±nÄ±z\n",
    "        CSV_FILE=\"/home/yapayzeka/ahsen_bulbul/data/cleaned10chunk.csv\",  # CSV dosya yolunuz\n",
    "        TOKEN_SIZE=384,  # Chunk boyutu\n",
    "        QDRANT_URL=\"http://localhost:6333\",  # Lokal Qdrant URL\n",
    "        COLLECTION_NAME=\"cohere_semantic_chunks\",\n",
    "        DIMENSION=1024\n",
    "    )\n",
    "    \n",
    "    # Pipeline oluÅŸtur\n",
    "    pipeline = YargitayPipeline(config)\n",
    "    \n",
    "    # MenÃ¼ gÃ¶ster\n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ğŸ›ï¸ YARGITAY SEMANTÄ°K CHUNK SÄ°STEMÄ°\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"1. Tam pipeline Ã§alÄ±ÅŸtÄ±r (CSV â†’ Semantic Chunks â†’ Qdrant)\")\n",
    "        print(\"2. Ä°nteraktif arama yap\")\n",
    "        print(\"3. Koleksiyon bilgilerini gÃ¶ster\")\n",
    "        print(\"4. Ã‡Ä±kÄ±ÅŸ\")\n",
    "        \n",
    "        choice = input(\"\\nSeÃ§iminiz (1-4): \")\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            csv_path = input(f\"CSV dosya yolu (Enter: {config.CSV_FILE}): \").strip()\n",
    "            if not csv_path:\n",
    "                csv_path = config.CSV_FILE\n",
    "            \n",
    "            success = pipeline.full_pipeline(csv_path)\n",
    "            if success:\n",
    "                print(\"âœ… Pipeline baÅŸarÄ±yla tamamlandÄ±!\")\n",
    "            else:\n",
    "                print(\"âŒ Pipeline hatasÄ±!\")\n",
    "        \n",
    "        elif choice == \"2\":\n",
    "            pipeline.interactive_search()\n",
    "        \n",
    "        elif choice == \"3\":\n",
    "            info = pipeline.processor.get_collection_info()\n",
    "            print(\"\\nğŸ“Š Koleksiyon Bilgileri:\")\n",
    "            print(json.dumps(info, indent=2, ensure_ascii=False))\n",
    "        \n",
    "        elif choice == \"4\":\n",
    "            print(\"ğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"âŒ GeÃ§ersiz seÃ§im!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bge-m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SemChunk + BGE-M3 + Qdrant Entegrasyon\n",
    "# YargÄ±tay KararlarÄ± iÃ§in Semantic Chunking Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import semchunk\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n",
    "import uuid\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "\n",
    "print(load_dotenv(\"/home/yapayzeka/ahsen_bulbul/qdrant/.env\"))\n",
    "\n",
    "# KonfigÃ¼rasyon\n",
    "@dataclass\n",
    "class Config:\n",
    "    # BGE-M3 ayarlarÄ±\n",
    "    BGE_MODEL_NAME: str = \"BAAI/bge-m3\"  # BGE-M3 model\n",
    "    USE_FP16: bool = True  # HafÄ±za optimizasyonu\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # SemChunk ayarlarÄ±\n",
    "    TOKEN_SIZE: int = 512  # Chunk boyutu (token)\n",
    "    ENCODING_NAME: str = \"cl100k_base\"  # Tiktoken encoding\n",
    "    \n",
    "    # Qdrant ayarlarÄ±\n",
    "    QDRANT_URL: str = \"http://localhost:6333\"  # Lokal Qdrant\n",
    "    COLLECTION_NAME: str = \"yargitay_bge_m3_chunks\"\n",
    "    EMBEDDING_DIM: int = 1024  # BGE-M3 dense embedding boyutu\n",
    "    \n",
    "    # Dosya ayarlarÄ±\n",
    "    CSV_FILE: str = \"/home/yapayzeka/ahsen_bulbul/data/cleaned10chunk.csv\"\n",
    "    BATCH_SIZE: int = 32  # BGE-M3 iÃ§in optimize edilmiÅŸ batch size\n",
    "\n",
    "class YargitaySemanticProcessor:\n",
    "    \"\"\"YargÄ±tay kararlarÄ± iÃ§in semantic chunking ve vector search\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        \n",
    "        # GPU/CPU kontrolÃ¼\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"ğŸš€ GPU kullanÄ±lÄ±yor: {torch.cuda.get_device_name()}\")\n",
    "        else:\n",
    "            print(\"ğŸ’» CPU kullanÄ±lÄ±yor\")\n",
    "        \n",
    "        # SemChunk chunker oluÅŸtur\n",
    "        self.encoding = tiktoken.get_encoding(config.ENCODING_NAME)\n",
    "        self.chunker = semchunk.chunkerify(self.encoding, config.TOKEN_SIZE)\n",
    "        \n",
    "        # BGE-M3 modelini yÃ¼kle\n",
    "        print(f\"ğŸ”® BGE-M3 modeli yÃ¼kleniyor... ({config.BGE_MODEL_NAME})\")\n",
    "        self.bge_model = BGEM3FlagModel(\n",
    "            config.BGE_MODEL_NAME, \n",
    "            use_fp16=config.USE_FP16,\n",
    "            device=config.DEVICE\n",
    "        )\n",
    "        \n",
    "        # Qdrant client oluÅŸtur\n",
    "        self.qdrant_client = QdrantClient(url=config.QDRANT_URL)\n",
    "        \n",
    "        print(f\"âœ… SemChunk chunker hazÄ±r (Token boyutu: {config.TOKEN_SIZE})\")\n",
    "        print(f\"âœ… BGE-M3 model hazÄ±r ({config.BGE_MODEL_NAME})\")\n",
    "        print(f\"âœ… Qdrant client hazÄ±r ({config.QDRANT_URL})\")\n",
    "    \n",
    "    def test_bge_connection(self):\n",
    "        \"\"\"BGE-M3 modelini test et\"\"\"\n",
    "        try:\n",
    "            test_text = [\"YargÄ±tay 6. Hukuk Dairesi'nin ihtiyati tedbir kararÄ±\"]\n",
    "            embeddings = self.bge_model.encode(test_text)\n",
    "            \n",
    "            # BGE-M3'den dense embedding al\n",
    "            dense_embedding = embeddings['dense_vecs'][0]\n",
    "            embedding_dim = len(dense_embedding)\n",
    "            \n",
    "            print(f\"âœ… BGE-M3 test baÅŸarÄ±lÄ± - Dense embedding boyutu: {embedding_dim}\")\n",
    "            print(f\"ğŸ” Sparse embedding mevcut: {'colbert_vecs' in embeddings}\")\n",
    "            return embedding_dim\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ BGE-M3 baÄŸlantÄ± hatasÄ±: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def create_qdrant_collection(self, recreate: bool = False):\n",
    "        \"\"\"Qdrant koleksiyonu oluÅŸtur\"\"\"\n",
    "        collection_name = self.config.COLLECTION_NAME\n",
    "        \n",
    "        # Koleksiyon varsa ve recreate True ise sil\n",
    "        if recreate:\n",
    "            try:\n",
    "                self.qdrant_client.delete_collection(collection_name)\n",
    "                print(f\"ğŸ—‘ï¸ Eski koleksiyon silindi: {collection_name}\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Koleksiyon yoksa oluÅŸtur\n",
    "        try:\n",
    "            collections = self.qdrant_client.get_collections().collections\n",
    "            collection_names = [c.name for c in collections]\n",
    "            \n",
    "            if collection_name not in collection_names:\n",
    "                self.qdrant_client.create_collection(\n",
    "                    collection_name=collection_name,\n",
    "                    vectors_config=VectorParams(\n",
    "                        size=self.config.EMBEDDING_DIM,\n",
    "                        distance=Distance.COSINE\n",
    "                    )\n",
    "                )\n",
    "                print(f\"âœ… Koleksiyon oluÅŸturuldu: {collection_name} (Boyut: {self.config.EMBEDDING_DIM})\")\n",
    "            else:\n",
    "                print(f\"â„¹ï¸ Koleksiyon zaten var: {collection_name}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Koleksiyon oluÅŸturma hatasÄ±: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def semantic_chunk_text(self, text: str, metadata: dict = None) -> List[Dict]:\n",
    "        \"\"\"Metni semantic olarak chunk'lara bÃ¶l\"\"\"\n",
    "        if not text or text.strip() == \"\":\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # SemChunk ile metni bÃ¶l\n",
    "            chunks = self.chunker(text)\n",
    "            \n",
    "            result_chunks = []\n",
    "            for i, chunk_text in enumerate(chunks):\n",
    "                if chunk_text.strip():  # BoÅŸ chunk'larÄ± atla\n",
    "                    chunk_data = {\n",
    "                        'chunk_id': i,\n",
    "                        'text': chunk_text.strip(),\n",
    "                        'token_count': len(self.encoding.encode(chunk_text)),\n",
    "                        'char_count': len(chunk_text),\n",
    "                    }\n",
    "                    \n",
    "                    # Metadata ekle\n",
    "                    if metadata:\n",
    "                        chunk_data.update(metadata)\n",
    "                    \n",
    "                    result_chunks.append(chunk_data)\n",
    "            \n",
    "            return result_chunks\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Chunking hatasÄ±: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def create_embeddings_bge(self, texts: List[str], batch_size: int = None) -> List[List[float]]:\n",
    "        \"\"\"Metinleri BGE-M3 ile embedding'e Ã§evir\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.BATCH_SIZE\n",
    "            \n",
    "        all_embeddings = []\n",
    "        \n",
    "        print(f\"ğŸ”® BGE-M3 ile {len(texts)} metin iÅŸleniyor...\")\n",
    "        \n",
    "        # BGE-M3 iÃ§in batch processing\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            \n",
    "            try:\n",
    "                # BGE-M3 ile embedding oluÅŸtur\n",
    "                embeddings_result = self.bge_model.encode(batch_texts)\n",
    "                \n",
    "                # Dense embedding'leri al (1024 boyut)\n",
    "                dense_embeddings = embeddings_result['dense_vecs']\n",
    "                \n",
    "                # List formatÄ±na Ã§evir\n",
    "                for embedding in dense_embeddings:\n",
    "                    all_embeddings.append(embedding.tolist())\n",
    "                \n",
    "                print(f\"  ğŸ“Š BGE-M3 Embedding: {i+len(batch_texts)}/{len(texts)}\")\n",
    "                \n",
    "                # GPU memory temizliÄŸi (gerekirse)\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ BGE-M3 Embedding hatasÄ± (batch {i//batch_size + 1}): {e}\")\n",
    "                # Hata durumunda sÄ±fÄ±r embedding ekle\n",
    "                for _ in batch_texts:\n",
    "                    all_embeddings.append([0.0] * self.config.EMBEDDING_DIM)\n",
    "        \n",
    "        return all_embeddings\n",
    "    \n",
    "    def process_csv_file(self, csv_path: str) -> List[Dict]:\n",
    "        \"\"\"CSV dosyasÄ±nÄ± iÅŸle ve chunk'larÄ± oluÅŸtur\"\"\"\n",
    "        print(f\"ğŸ“„ CSV dosyasÄ± okunuyor: {csv_path}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            print(f\"ğŸ“Š {len(df)} satÄ±r veri yÃ¼klendi\")\n",
    "            print(f\"ğŸ“‹ Mevcut sÃ¼tunlar: {df.columns.tolist()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ CSV okuma hatasÄ±: {e}\")\n",
    "            return []\n",
    "        \n",
    "        # Ana metin sÃ¼tununu belirle (Ã¶ncelik sÄ±rasÄ±na gÃ¶re)\n",
    "        text_columns = ['rawText', 'chunk_text', 'text', 'content', 'metin']\n",
    "        text_column = None\n",
    "        \n",
    "        for col in text_columns:\n",
    "            if col in df.columns:\n",
    "                text_column = col\n",
    "                print(f\"âœ… Ana metin sÃ¼tunu bulundu: '{col}'\")\n",
    "                break\n",
    "        \n",
    "        if not text_column:\n",
    "            print(f\"âŒ Ana metin sÃ¼tunu bulunamadÄ±. Kontrol edilen sÃ¼tunlar: {text_columns}\")\n",
    "            return []\n",
    "        \n",
    "        all_chunks = []\n",
    "        \n",
    "        print(\"ğŸ”„ Semantic chunking baÅŸlÄ±yor...\")\n",
    "        for idx, row in df.iterrows():\n",
    "            # Ana metni al\n",
    "            text = row.get(text_column, '')\n",
    "            \n",
    "            if not text or pd.isna(text):\n",
    "                print(f\"âš ï¸ SatÄ±r {idx}: BoÅŸ metin atlandÄ±\")\n",
    "                continue\n",
    "            \n",
    "            # Metadata hazÄ±rla (CSV yapÄ±nÄ±za gÃ¶re gÃ¼ncellenmiÅŸ)\n",
    "            metadata = {\n",
    "                'original_index': idx,\n",
    "                'esas_no': row.get('esasNo', ''),\n",
    "                'karar_no': row.get('kararNo', ''),\n",
    "                'daire': row.get('location', ''),\n",
    "                'tarih': row.get('extractedDates', ''),\n",
    "                'document_id': row.get('_id', ''),\n",
    "            }\n",
    "            \n",
    "            # Semantic chunking yap\n",
    "            chunks = self.semantic_chunk_text(str(text), metadata)\n",
    "            all_chunks.extend(chunks)\n",
    "            \n",
    "            # Progress gÃ¶ster\n",
    "            if (idx + 1) % 5 == 0:  # Daha sÄ±k progress gÃ¶ster (az veri olduÄŸu iÃ§in)\n",
    "                print(f\"  âœ… Ä°ÅŸlenen satÄ±r: {idx + 1}/{len(df)} (Toplam chunk: {len(all_chunks)})\")\n",
    "        \n",
    "        print(f\"ğŸ§© Toplam {len(all_chunks)} chunk oluÅŸturuldu\")\n",
    "        return all_chunks\n",
    "    \n",
    "    def upload_to_qdrant(self, chunks: List[Dict]):\n",
    "        \"\"\"Chunk'larÄ± Qdrant'a yÃ¼kle\"\"\"\n",
    "        if not chunks:\n",
    "            print(\"âŒ YÃ¼klenecek chunk yok\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸš€ {len(chunks)} chunk Qdrant'a yÃ¼kleniyor...\")\n",
    "        \n",
    "        # Metinleri topla\n",
    "        texts = [chunk['text'] for chunk in chunks]\n",
    "        \n",
    "        # BGE-M3 ile embedding'leri oluÅŸtur\n",
    "        print(\"ğŸ”® BGE-M3 embedding'ler oluÅŸturuluyor...\")\n",
    "        embeddings = self.create_embeddings_bge(texts)\n",
    "        \n",
    "        if len(embeddings) != len(chunks):\n",
    "            print(f\"âŒ Embedding sayÄ±sÄ± uyumsuz: {len(embeddings)} vs {len(chunks)}\")\n",
    "            return\n",
    "        \n",
    "        # Qdrant point'leri hazÄ±rla\n",
    "        points = []\n",
    "        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "            point = PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector=embedding,\n",
    "                payload=chunk\n",
    "            )\n",
    "            points.append(point)\n",
    "        \n",
    "        # Batch halinde yÃ¼kle\n",
    "        batch_size = self.config.BATCH_SIZE\n",
    "        print(f\"ğŸ“¦ {batch_size} batch size ile yÃ¼kleniyor...\")\n",
    "        \n",
    "        for i in range(0, len(points), batch_size):\n",
    "            batch = points[i:i + batch_size]\n",
    "            \n",
    "            try:\n",
    "                self.qdrant_client.upsert(\n",
    "                    collection_name=self.config.COLLECTION_NAME,\n",
    "                    points=batch\n",
    "                )\n",
    "                print(f\"  âœ… Batch yÃ¼klendi: {min(i + batch_size, len(points))}/{len(points)}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Batch yÃ¼kleme hatasÄ±: {e}\")\n",
    "        \n",
    "        print(\"ğŸ‰ YÃ¼kleme tamamlandÄ±!\")\n",
    "    \n",
    "    def search_semantic(self, query: str, limit: int = 10, score_threshold: float = 0.7) -> List[Dict]:\n",
    "        \"\"\"BGE-M3 ile semantic arama yap\"\"\"\n",
    "        print(f\"ğŸ” Arama: '{query}'\")\n",
    "        \n",
    "        try:\n",
    "            # Query'yi BGE-M3 ile vektÃ¶rize et\n",
    "            query_embeddings = self.bge_model.encode([query])\n",
    "            query_vector = query_embeddings['dense_vecs'][0].tolist()\n",
    "            \n",
    "            # Qdrant'ta ara (gÃ¼ncel query_points metodu)\n",
    "            search_results = self.qdrant_client.query_points(\n",
    "                collection_name=self.config.COLLECTION_NAME,\n",
    "                query=query_vector,\n",
    "                limit=limit,\n",
    "                score_threshold=score_threshold\n",
    "            )\n",
    "            \n",
    "            # SonuÃ§larÄ± formatla\n",
    "            results = []\n",
    "            for point in search_results.points:#burda muhtemel hata verir search_results olcak verirse\n",
    "                results.append({\n",
    "                    'score': point.score,\n",
    "                    'payload': point.payload\n",
    "                })\n",
    "            \n",
    "            print(f\"ğŸ“Š {len(results)} sonuÃ§ bulundu\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Arama hatasÄ±: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def advanced_search_with_filters(self, query: str, filters: Dict = None, limit: int = 10, score_threshold: float = 0.6) -> List[Dict]:\n",
    "        \"\"\"Filtreli arama yap\"\"\"\n",
    "        print(f\"ğŸ” Filtreli arama: '{query}' - Filtreler: {filters}\")\n",
    "        \n",
    "        try:\n",
    "            # Query'yi BGE-M3 ile vektÃ¶rize et\n",
    "            query_embeddings = self.bge_model.encode([query])\n",
    "            query_vector = query_embeddings['dense_vecs'][0].tolist()\n",
    "            \n",
    "            # Filter oluÅŸtur\n",
    "            query_filter = None\n",
    "            if filters:\n",
    "                from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "                conditions = []\n",
    "                for key, value in filters.items():\n",
    "                    conditions.append(FieldCondition(key=key, match=MatchValue(value=value)))\n",
    "                query_filter = Filter(must=conditions)\n",
    "            \n",
    "            # Qdrant'ta filtreli arama yap\n",
    "            search_results = self.qdrant_client.query_points(\n",
    "                collection_name=self.config.COLLECTION_NAME,\n",
    "                query=query_vector,\n",
    "                query_filter=query_filter,\n",
    "                limit=limit,\n",
    "                score_threshold=score_threshold\n",
    "            )\n",
    "            \n",
    "            # SonuÃ§larÄ± formatla\n",
    "            results = []\n",
    "            for point in search_results.points:\n",
    "                results.append({\n",
    "                    'score': point.score,\n",
    "                    'payload': point.payload\n",
    "                })\n",
    "            \n",
    "            print(f\"ğŸ“Š {len(results)} filtreli sonuÃ§ bulundu\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Filtreli arama hatasÄ±: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_collection_info(self) -> dict:\n",
    "        \"\"\"Koleksiyon bilgilerini al\"\"\"\n",
    "        try:\n",
    "            info = self.qdrant_client.get_collection(self.config.COLLECTION_NAME)\n",
    "            return {\n",
    "                \"collection_name\": self.config.COLLECTION_NAME,\n",
    "                \"points_count\": info.points_count,\n",
    "                \"vectors_count\": info.vectors_count,\n",
    "                \"status\": info.status,\n",
    "                \"embedding_model\": \"BGE-M3\",\n",
    "                \"embedding_dim\": self.config.EMBEDDING_DIM\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "# Ana Pipeline SÄ±nÄ±fÄ±\n",
    "class YargitayPipeline:\n",
    "    \"\"\"Ana pipeline sÄ±nÄ±fÄ±\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.processor = YargitaySemanticProcessor(config)\n",
    "        self.config = config\n",
    "    \n",
    "    def full_pipeline(self, csv_path: str = None):\n",
    "        \"\"\"Tam pipeline'Ä± Ã§alÄ±ÅŸtÄ±r\"\"\"\n",
    "        csv_path = csv_path or self.config.CSV_FILE\n",
    "        \n",
    "        print(\"ğŸš€ YargÄ±tay BGE-M3 Semantic Pipeline BaÅŸlÄ±yor\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # 1. BGE-M3 modelini test et\n",
    "        embedding_dim = self.processor.test_bge_connection()\n",
    "        if not embedding_dim:\n",
    "            return False\n",
    "        \n",
    "        # 2. Koleksiyon oluÅŸtur\n",
    "        self.processor.create_qdrant_collection(recreate=True)\n",
    "        \n",
    "        # 3. CSV'yi iÅŸle\n",
    "        chunks = self.processor.process_csv_file(csv_path)\n",
    "        if not chunks:\n",
    "            print(\"âŒ Ä°ÅŸlenecek chunk bulunamadÄ±\")\n",
    "            return False\n",
    "        \n",
    "        # 4. Qdrant'a yÃ¼kle\n",
    "        self.processor.upload_to_qdrant(chunks)\n",
    "        \n",
    "        # 5. Bilgileri gÃ¶ster\n",
    "        info = self.processor.get_collection_info()\n",
    "        print(\"\\nğŸ“Š Koleksiyon Bilgileri:\")\n",
    "        print(json.dumps(info, indent=2, ensure_ascii=False))\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def interactive_search(self):\n",
    "        \"\"\"Ä°nteraktif arama arayÃ¼zÃ¼\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ğŸ›ï¸ YARGITAY BGE-M3 SEMANTÄ°K ARAMA SÄ°STEMÄ°\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        while True:\n",
    "            print(\"\\nğŸ” Arama SeÃ§enekleri:\")\n",
    "            print(\"1. Basit arama\")\n",
    "            print(\"2. Filtreli arama\")\n",
    "            print(\"3. Ana menÃ¼ye dÃ¶n\")\n",
    "            \n",
    "            search_choice = input(\"SeÃ§iminiz (1-3): \")\n",
    "            \n",
    "            if search_choice == \"3\":\n",
    "                break\n",
    "            elif search_choice not in [\"1\", \"2\"]:\n",
    "                print(\"âŒ GeÃ§ersiz seÃ§im!\")\n",
    "                continue\n",
    "            \n",
    "            query = input(\"\\nğŸ” Arama metni (Ã§Ä±kmak iÃ§in 'q'): \")\n",
    "            if query.lower() in ['q', 'quit', 'exit']:\n",
    "                break\n",
    "            \n",
    "            if not query.strip():\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                limit = int(input(\"ğŸ“Š KaÃ§ sonuÃ§? (varsayÄ±lan 5): \") or \"5\")\n",
    "                #threshold = float(input(\"ğŸ¯ Minimum benzerlik skoru? (varsayÄ±lan 0.6): \") or \"0.6\")\n",
    "            except:\n",
    "                limit = 5\n",
    "                #threshold = 0.6\n",
    "            \n",
    "            # Arama tipini belirle\n",
    "            if search_choice == \"1\":\n",
    "                results = self.processor.search_semantic(query, limit=limit)\n",
    "            else:\n",
    "                # Filtreli arama\n",
    "                print(\"\\nğŸ”§ Filtre SeÃ§enekleri (boÅŸ bÄ±rakabilirsiniz):\")\n",
    "                daire_filter = input(\"Daire filtresi (Ã¶rn: '6. Hukuk Dairesi'): \").strip()\n",
    "                \n",
    "                filters = {}\n",
    "                if daire_filter:\n",
    "                    filters['daire'] = daire_filter\n",
    "                \n",
    "                results = self.processor.advanced_search_with_filters(\n",
    "                    query, filters=filters if filters else None, \n",
    "                    limit=limit\n",
    "                )\n",
    "            \n",
    "            if not results:\n",
    "                print(\"âŒ SonuÃ§ bulunamadÄ±\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nğŸ“‹ {len(results)} sonuÃ§ bulundu:\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            for i, result in enumerate(results, 1):\n",
    "                payload = result['payload']\n",
    "                print(f\"\\n{i}. ğŸ“„ BGE-M3 Benzerlik Skoru: {result['score']:.3f}\")\n",
    "                print(f\"   âš–ï¸ Esas No: {payload.get('esas_no', 'N/A')}\")\n",
    "                print(f\"   ğŸ“‹ Karar No: {payload.get('karar_no', 'N/A')}\")\n",
    "                print(f\"   ğŸ›ï¸ Daire: {payload.get('daire', 'N/A')}\")\n",
    "                print(f\"   ğŸ“… Tarih: {payload.get('tarih', 'N/A')}\")\n",
    "                print(f\"   ğŸ”¤ Token: {payload.get('token_count', 'N/A')}\")\n",
    "                print(f\"   ğŸ“ Metin Ã–nizleme:\")\n",
    "                \n",
    "                text = payload.get('text', '')\n",
    "                preview = text[:300] + \"...\" if len(text) > 300 else text\n",
    "                print(f\"      {preview}\")\n",
    "                print(\"-\" * 60)\n",
    "\n",
    "# KullanÄ±m Ã¶rneÄŸi ve main fonksiyon\n",
    "def main():\n",
    "    \"\"\"Ana fonksiyon\"\"\"\n",
    "    \n",
    "    # KonfigÃ¼rasyon\n",
    "    config = Config(\n",
    "        CSV_FILE=\"/home/yapayzeka/ahsen_bulbul/data/cleaned10chunk.csv\",\n",
    "        TOKEN_SIZE=512,  # Chunk boyutu\n",
    "        QDRANT_URL=\"http://localhost:6333\",\n",
    "        COLLECTION_NAME=\"bge_m3_chunks\",\n",
    "        EMBEDDING_DIM=1024,\n",
    "        BATCH_SIZE=16,  # GPU memory'ye gÃ¶re ayarlayÄ±n\n",
    "        USE_FP16=True,\n",
    "        DEVICE=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "    \n",
    "    # Pipeline oluÅŸtur\n",
    "    pipeline = YargitayPipeline(config)\n",
    "    \n",
    "    # MenÃ¼ gÃ¶ster\n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ğŸ›ï¸ YARGITAY BGE-M3 SEMANTÄ°K CHUNK SÄ°STEMÄ°\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"1. Tam pipeline Ã§alÄ±ÅŸtÄ±r (CSV â†’ Semantic Chunks â†’ BGE-M3 â†’ Qdrant)\")\n",
    "        print(\"2. Ä°nteraktif arama yap\")\n",
    "        print(\"3. Koleksiyon bilgilerini gÃ¶ster\")\n",
    "        print(\"4. Ã‡Ä±kÄ±ÅŸ\")\n",
    "        \n",
    "        choice = input(\"\\nSeÃ§iminiz (1-4): \")\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            csv_path = input(f\"CSV dosya yolu (Enter: {config.CSV_FILE}): \").strip()\n",
    "            if not csv_path:\n",
    "                csv_path = config.CSV_FILE\n",
    "            \n",
    "            success = pipeline.full_pipeline(csv_path)\n",
    "            if success:\n",
    "                print(\"âœ… BGE-M3 Pipeline baÅŸarÄ±yla tamamlandÄ±!\")\n",
    "            else:\n",
    "                print(\"âŒ Pipeline hatasÄ±!\")\n",
    "        \n",
    "        elif choice == \"2\":\n",
    "            pipeline.interactive_search()\n",
    "        \n",
    "        elif choice == \"3\":\n",
    "            info = pipeline.processor.get_collection_info()\n",
    "            print(\"\\nğŸ“Š Koleksiyon Bilgileri:\")\n",
    "            print(json.dumps(info, indent=2, ensure_ascii=False))\n",
    "        \n",
    "        elif choice == \"4\":\n",
    "            print(\"ğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"âŒ GeÃ§ersiz seÃ§im!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # BGE-M3 kurulumu kontrolÃ¼\n",
    "    try:\n",
    "        from FlagEmbedding import BGEM3FlagModel\n",
    "        print(\"âœ… FlagEmbedding kÃ¼tÃ¼phanesi yÃ¼klÃ¼\")\n",
    "    except ImportError:\n",
    "        print(\"âŒ FlagEmbedding kÃ¼tÃ¼phanesi bulunamadÄ±!\")\n",
    "        print(\"Kurulum iÃ§in: pip install FlagEmbedding\")\n",
    "        exit(1)\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "âœ… FlagEmbedding kÃ¼tÃ¼phanesi yÃ¼klÃ¼\n",
      "ğŸš€ GPU kullanÄ±lÄ±yor: NVIDIA RTX A6000\n",
      "ğŸ”® BGE-M3 modeli yÃ¼kleniyor... (BAAI/bge-m3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 50091.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SemChunk chunker hazÄ±r (Token boyutu: 512)\n",
      "âœ… BGE-M3 model hazÄ±r (BAAI/bge-m3)\n",
      "âœ… Qdrant client hazÄ±r (http://localhost:6333)\n",
      "\n",
      "==================================================\n",
      "ğŸ›ï¸ YARGITAY BGE-M3 SEMANTÄ°K CHUNK SÄ°STEMÄ°\n",
      "==================================================\n",
      "1. Tam pipeline Ã§alÄ±ÅŸtÄ±r (CSV â†’ Semantic Chunks â†’ BGE-M3 â†’ Qdrant)\n",
      "2. Ä°nteraktif arama yap\n",
      "3. Koleksiyon bilgilerini gÃ¶ster\n",
      "4. Ã‡Ä±kÄ±ÅŸ\n",
      "\n",
      "==================================================\n",
      "ğŸ›ï¸ YARGITAY BGE-M3 SEMANTÄ°K ARAMA SÄ°STEMÄ°\n",
      "==================================================\n",
      "\n",
      "ğŸ” Arama SeÃ§enekleri:\n",
      "1. Basit arama\n",
      "2. Filtreli arama\n",
      "3. Ana menÃ¼ye dÃ¶n\n",
      "ğŸ” Arama: 'ihtiyati tedbir tazminat'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š 5 sonuÃ§ bulundu\n",
      "\n",
      "ğŸ“‹ 5 sonuÃ§ bulundu:\n",
      "------------------------------------------------------------\n",
      "\n",
      "1. ğŸ“„ BGE-M3 Benzerlik Skoru: 0.668\n",
      "   âš–ï¸ Esas No: 2022/3281 E.\n",
      "   ğŸ“‹ Karar No: 2024/117 K.\n",
      "   ğŸ›ï¸ Daire: 6.HukukDairesisi\n",
      "   ğŸ“… Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   ğŸ”¤ Token: 413\n",
      "   ğŸ“ Metin Ã–nizleme:\n",
      "      maddesi, ihtiyati tedbir kararÄ±nÄ±n haksÄ±z olduÄŸunun belirlenmesi halinde tedbir kararÄ± yÃ¼zÃ¼nden uÄŸranÄ±lan zararÄ±n tazminini dÃ¼zenlediÄŸini, ihtiyati tedbir kararÄ±nÄ± icra ettiren tarafÄ±n yasal sÃ¼rede dava aÃ§mamasÄ± halinde ihtiyati tedbirin haksÄ±z konulduÄŸunun kabulÃ¼ gerektiÄŸi, kaldÄ± ki sÃ¼resinde dava ...\n",
      "------------------------------------------------------------\n",
      "\n",
      "2. ğŸ“„ BGE-M3 Benzerlik Skoru: 0.649\n",
      "   âš–ï¸ Esas No: 2022/3281 E.\n",
      "   ğŸ“‹ Karar No: 2024/117 K.\n",
      "   ğŸ›ï¸ Daire: 6.HukukDairesisi\n",
      "   ğŸ“… Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   ğŸ”¤ Token: 431\n",
      "   ğŸ“ Metin Ã–nizleme:\n",
      "      3. DeÄŸerlendirme Mahkemece, tazminat davalÄ±sÄ±nÄ±n Ã¶demekle yÃ¼kÃ¼mlÃ¼ olduÄŸu miktarÄ±n uyulmasÄ±na karar verilen YargÄ±tay ilamÄ±nda da belirtildiÄŸi Ã¼zer ihtiyati tedbir kararÄ±nÄ±n icra edildiÄŸi tarih ile ihtiyati tedbirin kalktÄ±ÄŸÄ± ya da kalkmÄ±ÅŸ sayÄ±ldÄ±ÄŸÄ± tarih arasÄ±ndaki zarar olduÄŸu, ihtiyati tedbir kararÄ±...\n",
      "------------------------------------------------------------\n",
      "\n",
      "3. ğŸ“„ BGE-M3 Benzerlik Skoru: 0.620\n",
      "   âš–ï¸ Esas No: 2022/3281 E.\n",
      "   ğŸ“‹ Karar No: 2024/117 K.\n",
      "   ğŸ›ï¸ Daire: 6.HukukDairesisi\n",
      "   ğŸ“… Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   ğŸ”¤ Token: 290\n",
      "   ğŸ“ Metin Ã–nizleme:\n",
      "      maddesi hÃ¼kmÃ¼ne aykÄ±rÄ± olarak ihtiyati tedbire iliÅŸkin karar tarihinden itibaren 10 gÃ¼n iÃ§inde dava aÃ§Ä±lmamÄ±ÅŸ olduÄŸu, haksÄ±z ihtiyati tedbirden dolayÄ± olan sorumluluÄŸun kusursuz sorumluluk olduÄŸu, yani, haksÄ±z ihtiyati tedbir koydurtmuÅŸ olan tarafÄ±n, bundan doÄŸan maddi zararla sorumlu tutulabilmesi ...\n",
      "------------------------------------------------------------\n",
      "\n",
      "4. ğŸ“„ BGE-M3 Benzerlik Skoru: 0.609\n",
      "   âš–ï¸ Esas No: 2022/3281 E.\n",
      "   ğŸ“‹ Karar No: 2024/117 K.\n",
      "   ğŸ›ï¸ Daire: 6.HukukDairesisi\n",
      "   ğŸ“… Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   ğŸ”¤ Token: 409\n",
      "   ğŸ“ Metin Ã–nizleme:\n",
      "      maddesindeki on gÃ¼nlÃ¼k sÃ¼re iÃ§erisinde esas hakkÄ±nda dava aÃ§mazsa, ihtiyati tedbirin haksÄ±z konulmuÅŸ sayÄ±lacaÄŸÄ±, haksÄ±z ihtiyati tedbirden dolayÄ± tazminat davasÄ± aÃ§an davacÄ±nÄ±n Ã¶denmesini istediÄŸi zararÄ± ile haksÄ±z ihtiyati tedbir arasÄ±nda uygun illiyet (nedensellik) baÄŸÄ± (sebep sonuÃ§ iliÅŸkisi) bulu...\n",
      "------------------------------------------------------------\n",
      "\n",
      "5. ğŸ“„ BGE-M3 Benzerlik Skoru: 0.607\n",
      "   âš–ï¸ Esas No: 2022/3281 E.\n",
      "   ğŸ“‹ Karar No: 2024/117 K.\n",
      "   ğŸ›ï¸ Daire: 6.HukukDairesisi\n",
      "   ğŸ“… Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   ğŸ”¤ Token: 422\n",
      "   ğŸ“ Metin Ã–nizleme:\n",
      "      6. Hukuk Dairesi 2022/3281 E. , 2024/117 K. \\n \"Ä°Ã§tihat Metni\" MAHKEMESÄ° :Asliye Hukuk Mahkemesi Taraflar arasÄ±ndaki tazminat davasÄ±ndan dolayÄ± yapÄ±lan yargÄ±lama sonunda Ä°lk Derece Mahkemesince davanÄ±n reddine karar verilmiÅŸtir. Ä°lk Derece Mahkemesi kararÄ± davacÄ±lar vekilince temyiz edilmekle; kesin...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ” Arama SeÃ§enekleri:\n",
      "1. Basit arama\n",
      "2. Filtreli arama\n",
      "3. Ana menÃ¼ye dÃ¶n\n",
      "ğŸ” Arama: 'inÅŸaat davasÄ±'\n",
      "ğŸ“Š 5 sonuÃ§ bulundu\n",
      "\n",
      "ğŸ“‹ 5 sonuÃ§ bulundu:\n",
      "------------------------------------------------------------\n",
      "\n",
      "1. ğŸ“„ BGE-M3 Benzerlik Skoru: 0.575\n",
      "   âš–ï¸ Esas No: 2022/3993 E.\n",
      "   ğŸ“‹ Karar No: 2024/775 K.\n",
      "   ğŸ›ï¸ Daire: 6.HukukDairesisi\n",
      "   ğŸ“… Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   ğŸ”¤ Token: 492\n",
      "   ğŸ“ Metin Ã–nizleme:\n",
      "      BÃ¶lge Adliye Mahkemesinin yukarÄ±da belirtilen kararÄ±na karÅŸÄ± sÃ¼resi iÃ§inde davalÄ± ... vekili temyiz isteminde bulunmuÅŸtur. 2. Dairemizin 17.02.2022 tarihli ve 2021/2532 Esas, 2022/901 Karar sayÄ±lÄ± ilamÄ±yla; \"Mahkemece davalÄ± ... hakkÄ±ndaki tapu iptali ve tescil kararÄ± davalÄ± yÃ¼klenici ÅŸirketin arsa ...\n",
      "------------------------------------------------------------\n",
      "\n",
      "2. ğŸ“„ BGE-M3 Benzerlik Skoru: 0.566\n",
      "   âš–ï¸ Esas No: 2022/3993 E.\n",
      "   ğŸ“‹ Karar No: 2024/775 K.\n",
      "   ğŸ›ï¸ Daire: 6.HukukDairesisi\n",
      "   ğŸ“… Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   ğŸ”¤ Token: 153\n",
      "   ğŸ“ Metin Ã–nizleme:\n",
      "      kiÅŸilere devretse bile 3. kiÅŸi ve daha sonraki devralanlarÄ±n iyiniyet savunmasÄ±nda bulunmasÄ±nÄ±n mÃ¼mkÃ¼n olmadÄ±ÄŸÄ±nÄ±, davalÄ± ...â€™Ä±n yÃ¼kleniciye kat karÅŸÄ±lÄ±ÄŸÄ± inÅŸaat sÃ¶zleÅŸmesi gereÄŸi avans olarak verilmiÅŸ arsa Ã¼zerine yapÄ±lmÄ±ÅŸ binadan baÄŸÄ±msÄ±z bÃ¶lÃ¼m edinmeyi amaÃ§ladÄ±ÄŸÄ±nÄ±, bunun iÃ§in de diÄŸer davalÄ± ......\n",
      "------------------------------------------------------------\n",
      "\n",
      "3. ğŸ“„ BGE-M3 Benzerlik Skoru: 0.565\n",
      "   âš–ï¸ Esas No: 2022/3281 E.\n",
      "   ğŸ“‹ Karar No: 2024/117 K.\n",
      "   ğŸ›ï¸ Daire: 6.HukukDairesisi\n",
      "   ğŸ“… Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   ğŸ”¤ Token: 409\n",
      "   ğŸ“ Metin Ã–nizleme:\n",
      "      maddesindeki on gÃ¼nlÃ¼k sÃ¼re iÃ§erisinde esas hakkÄ±nda dava aÃ§mazsa, ihtiyati tedbirin haksÄ±z konulmuÅŸ sayÄ±lacaÄŸÄ±, haksÄ±z ihtiyati tedbirden dolayÄ± tazminat davasÄ± aÃ§an davacÄ±nÄ±n Ã¶denmesini istediÄŸi zararÄ± ile haksÄ±z ihtiyati tedbir arasÄ±nda uygun illiyet (nedensellik) baÄŸÄ± (sebep sonuÃ§ iliÅŸkisi) bulu...\n",
      "------------------------------------------------------------\n",
      "\n",
      "4. ğŸ“„ BGE-M3 Benzerlik Skoru: 0.560\n",
      "   âš–ï¸ Esas No: 2022/3281 E.\n",
      "   ğŸ“‹ Karar No: 2024/117 K.\n",
      "   ğŸ›ï¸ Daire: 6.HukukDairesisi\n",
      "   ğŸ“… Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   ğŸ”¤ Token: 422\n",
      "   ğŸ“ Metin Ã–nizleme:\n",
      "      6. Hukuk Dairesi 2022/3281 E. , 2024/117 K. \\n \"Ä°Ã§tihat Metni\" MAHKEMESÄ° :Asliye Hukuk Mahkemesi Taraflar arasÄ±ndaki tazminat davasÄ±ndan dolayÄ± yapÄ±lan yargÄ±lama sonunda Ä°lk Derece Mahkemesince davanÄ±n reddine karar verilmiÅŸtir. Ä°lk Derece Mahkemesi kararÄ± davacÄ±lar vekilince temyiz edilmekle; kesin...\n",
      "------------------------------------------------------------\n",
      "\n",
      "5. ğŸ“„ BGE-M3 Benzerlik Skoru: 0.556\n",
      "   âš–ï¸ Esas No: 2023/576 E.\n",
      "   ğŸ“‹ Karar No: 2024/399 K.\n",
      "   ğŸ›ï¸ Daire: 6.HukukDairesisi\n",
      "   ğŸ“… Tarih: 30.01.2024,15.07.2017,24.04.2013,24.01.2023,30.01.2024\n",
      "   ğŸ”¤ Token: 448\n",
      "   ğŸ“ Metin Ã–nizleme:\n",
      "      vekili cevap dilekÃ§esinde Ã¶zetle; ....A.Å.'nin diÄŸer davalÄ± ÅŸirket ile yapmÄ±ÅŸ olduÄŸu sÃ¶zleÅŸme Ã§erÃ§evesinde davacÄ±ya dava konusu villanÄ±n satÄ±ldÄ±ÄŸÄ±nÄ± ve teslim edildiÄŸini, dava konusu villanÄ±n tapusunun diÄŸer davalÄ± ÅŸirket Ã¼zerinde olup davacÄ±ya tapu devrinin gerektiÄŸini savunarak, davanÄ±n reddini is...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ” Arama SeÃ§enekleri:\n",
      "1. Basit arama\n",
      "2. Filtreli arama\n",
      "3. Ana menÃ¼ye dÃ¶n\n",
      "\n",
      "==================================================\n",
      "ğŸ›ï¸ YARGITAY BGE-M3 SEMANTÄ°K CHUNK SÄ°STEMÄ°\n",
      "==================================================\n",
      "1. Tam pipeline Ã§alÄ±ÅŸtÄ±r (CSV â†’ Semantic Chunks â†’ BGE-M3 â†’ Qdrant)\n",
      "2. Ä°nteraktif arama yap\n",
      "3. Koleksiyon bilgilerini gÃ¶ster\n",
      "4. Ã‡Ä±kÄ±ÅŸ\n",
      "ğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!\n"
     ]
    }
   ],
   "source": [
    "# SemChunk + BGE-M3 + Qdrant Entegrasyon\n",
    "# YargÄ±tay KararlarÄ± iÃ§in Semantic Chunking Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import semchunk\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n",
    "import uuid\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "\n",
    "print(load_dotenv(\"/home/yapayzeka/ahsen_bulbul/qdrant/.env\"))\n",
    "\n",
    "# KonfigÃ¼rasyon\n",
    "@dataclass\n",
    "class Config:\n",
    "    # BGE-M3 ayarlarÄ±\n",
    "    BGE_MODEL_NAME: str = \"BAAI/bge-m3\"  # BGE-M3 model\n",
    "    USE_FP16: bool = True  # HafÄ±za optimizasyonu\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # SemChunk ayarlarÄ±\n",
    "    TOKEN_SIZE: int = 512  # Chunk boyutu (token)\n",
    "    ENCODING_NAME: str = \"cl100k_base\"  # Tiktoken encoding\n",
    "    \n",
    "    # Qdrant ayarlarÄ±\n",
    "    QDRANT_URL: str = \"http://localhost:6333\"  # Lokal Qdrant\n",
    "    COLLECTION_NAME: str = \"yargitay_bge_m3_chunks\"\n",
    "    EMBEDDING_DIM: int = 1024  # BGE-M3 dense embedding boyutu\n",
    "    \n",
    "    # Dosya ayarlarÄ±\n",
    "    CSV_FILE: str = \"/home/yapayzeka/ahsen_bulbul/data/cleaned10chunk.csv\"\n",
    "    BATCH_SIZE: int = 32  # BGE-M3 iÃ§in optimize edilmiÅŸ batch size\n",
    "\n",
    "class YargitaySemanticProcessor:\n",
    "    \"\"\"YargÄ±tay kararlarÄ± iÃ§in semantic chunking ve vector search\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        \n",
    "        # GPU/CPU kontrolÃ¼\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"ğŸš€ GPU kullanÄ±lÄ±yor: {torch.cuda.get_device_name()}\")\n",
    "        else:\n",
    "            print(\"ğŸ’» CPU kullanÄ±lÄ±yor\")\n",
    "        \n",
    "        # SemChunk chunker oluÅŸtur\n",
    "        self.encoding = tiktoken.get_encoding(config.ENCODING_NAME)\n",
    "        self.chunker = semchunk.chunkerify(self.encoding, config.TOKEN_SIZE)\n",
    "        \n",
    "        # BGE-M3 modelini yÃ¼kle\n",
    "        print(f\"ğŸ”® BGE-M3 modeli yÃ¼kleniyor... ({config.BGE_MODEL_NAME})\")\n",
    "        self.bge_model = BGEM3FlagModel(\n",
    "            config.BGE_MODEL_NAME, \n",
    "            use_fp16=config.USE_FP16,\n",
    "            device=config.DEVICE\n",
    "        )\n",
    "        \n",
    "        # Qdrant client oluÅŸtur\n",
    "        self.qdrant_client = QdrantClient(url=config.QDRANT_URL)\n",
    "        \n",
    "        print(f\"âœ… SemChunk chunker hazÄ±r (Token boyutu: {config.TOKEN_SIZE})\")\n",
    "        print(f\"âœ… BGE-M3 model hazÄ±r ({config.BGE_MODEL_NAME})\")\n",
    "        print(f\"âœ… Qdrant client hazÄ±r ({config.QDRANT_URL})\")\n",
    "    \n",
    "    def test_bge_connection(self):\n",
    "        \"\"\"BGE-M3 modelini test et\"\"\"\n",
    "        try:\n",
    "            test_text = [\"YargÄ±tay 6. Hukuk Dairesi'nin ihtiyati tedbir kararÄ±\"]\n",
    "            embeddings = self.bge_model.encode(test_text)\n",
    "            \n",
    "            # BGE-M3'den dense embedding al\n",
    "            dense_embedding = embeddings['dense_vecs'][0]\n",
    "            embedding_dim = len(dense_embedding)\n",
    "            \n",
    "            print(f\"âœ… BGE-M3 test baÅŸarÄ±lÄ± - Dense embedding boyutu: {embedding_dim}\")\n",
    "            print(f\"ğŸ” Sparse embedding mevcut: {'colbert_vecs' in embeddings}\")\n",
    "            return embedding_dim\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ BGE-M3 baÄŸlantÄ± hatasÄ±: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def create_qdrant_collection(self, recreate: bool = False):\n",
    "        \"\"\"Qdrant koleksiyonu oluÅŸtur\"\"\"\n",
    "        collection_name = self.config.COLLECTION_NAME\n",
    "        \n",
    "        # Koleksiyon varsa ve recreate True ise sil\n",
    "        if recreate:\n",
    "            try:\n",
    "                self.qdrant_client.delete_collection(collection_name)\n",
    "                print(f\"ğŸ—‘ï¸ Eski koleksiyon silindi: {collection_name}\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Koleksiyon yoksa oluÅŸtur\n",
    "        try:\n",
    "            collections = self.qdrant_client.get_collections().collections\n",
    "            collection_names = [c.name for c in collections]\n",
    "            \n",
    "            if collection_name not in collection_names:\n",
    "                self.qdrant_client.create_collection(\n",
    "                    collection_name=collection_name,\n",
    "                    vectors_config=VectorParams(\n",
    "                        size=self.config.EMBEDDING_DIM,\n",
    "                        distance=Distance.COSINE\n",
    "                    )\n",
    "                )\n",
    "                print(f\"âœ… Koleksiyon oluÅŸturuldu: {collection_name} (Boyut: {self.config.EMBEDDING_DIM})\")\n",
    "            else:\n",
    "                print(f\"â„¹ï¸ Koleksiyon zaten var: {collection_name}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Koleksiyon oluÅŸturma hatasÄ±: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def semantic_chunk_text(self, text: str, metadata: dict = None) -> List[Dict]:\n",
    "        \"\"\"Metni semantic olarak chunk'lara bÃ¶l\"\"\"\n",
    "        if not text or text.strip() == \"\":\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # SemChunk ile metni bÃ¶l\n",
    "            chunks = self.chunker(text)\n",
    "            \n",
    "            result_chunks = []\n",
    "            for i, chunk_text in enumerate(chunks):\n",
    "                if chunk_text.strip():  # BoÅŸ chunk'larÄ± atla\n",
    "                    chunk_data = {\n",
    "                        'chunk_id': i,\n",
    "                        'text': chunk_text.strip(),\n",
    "                        'token_count': len(self.encoding.encode(chunk_text)),\n",
    "                        'char_count': len(chunk_text),\n",
    "                    }\n",
    "                    \n",
    "                    # Metadata ekle\n",
    "                    if metadata:\n",
    "                        chunk_data.update(metadata)\n",
    "                    \n",
    "                    result_chunks.append(chunk_data)\n",
    "            \n",
    "            return result_chunks\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Chunking hatasÄ±: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def create_embeddings_bge(self, texts: List[str], batch_size: int = None) -> List[List[float]]:\n",
    "        \"\"\"Metinleri BGE-M3 ile embedding'e Ã§evir\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.BATCH_SIZE\n",
    "            \n",
    "        all_embeddings = []\n",
    "        \n",
    "        print(f\"ğŸ”® BGE-M3 ile {len(texts)} metin iÅŸleniyor...\")\n",
    "        \n",
    "        # BGE-M3 iÃ§in batch processing\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            \n",
    "            try:\n",
    "                # BGE-M3 ile embedding oluÅŸtur\n",
    "                embeddings_result = self.bge_model.encode(batch_texts)\n",
    "                \n",
    "                # Dense embedding'leri al (1024 boyut)\n",
    "                dense_embeddings = embeddings_result['dense_vecs']\n",
    "                \n",
    "                # List formatÄ±na Ã§evir\n",
    "                for embedding in dense_embeddings:\n",
    "                    all_embeddings.append(embedding.tolist())\n",
    "                \n",
    "                print(f\"  ğŸ“Š BGE-M3 Embedding: {i+len(batch_texts)}/{len(texts)}\")\n",
    "                \n",
    "                # GPU memory temizliÄŸi (gerekirse)\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ BGE-M3 Embedding hatasÄ± (batch {i//batch_size + 1}): {e}\")\n",
    "                # Hata durumunda sÄ±fÄ±r embedding ekle\n",
    "                for _ in batch_texts:\n",
    "                    all_embeddings.append([0.0] * self.config.EMBEDDING_DIM)\n",
    "        \n",
    "        return all_embeddings\n",
    "    \n",
    "    def process_csv_file(self, csv_path: str) -> List[Dict]:\n",
    "        \"\"\"CSV dosyasÄ±nÄ± iÅŸle ve chunk'larÄ± oluÅŸtur\"\"\"\n",
    "        print(f\"ğŸ“„ CSV dosyasÄ± okunuyor: {csv_path}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            print(f\"ğŸ“Š {len(df)} satÄ±r veri yÃ¼klendi\")\n",
    "            print(f\"ğŸ“‹ Mevcut sÃ¼tunlar: {df.columns.tolist()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ CSV okuma hatasÄ±: {e}\")\n",
    "            return []\n",
    "        \n",
    "        # Ana metin sÃ¼tununu belirle (Ã¶ncelik sÄ±rasÄ±na gÃ¶re)\n",
    "        text_columns = ['rawText', 'chunk_text', 'text', 'content', 'metin']\n",
    "        text_column = None\n",
    "        \n",
    "        for col in text_columns:\n",
    "            if col in df.columns:\n",
    "                text_column = col\n",
    "                print(f\"âœ… Ana metin sÃ¼tunu bulundu: '{col}'\")\n",
    "                break\n",
    "        \n",
    "        if not text_column:\n",
    "            print(f\"âŒ Ana metin sÃ¼tunu bulunamadÄ±. Kontrol edilen sÃ¼tunlar: {text_columns}\")\n",
    "            return []\n",
    "        \n",
    "        all_chunks = []\n",
    "        \n",
    "        print(\"ğŸ”„ Semantic chunking baÅŸlÄ±yor...\")\n",
    "        for idx, row in df.iterrows():\n",
    "            # Ana metni al\n",
    "            text = row.get(text_column, '')\n",
    "            \n",
    "            if not text or pd.isna(text):\n",
    "                print(f\"âš ï¸ SatÄ±r {idx}: BoÅŸ metin atlandÄ±\")\n",
    "                continue\n",
    "            \n",
    "            # Metadata hazÄ±rla (CSV yapÄ±nÄ±za gÃ¶re gÃ¼ncellenmiÅŸ)\n",
    "            metadata = {\n",
    "                'original_index': idx,\n",
    "                'esas_no': row.get('esasNo', '') or row.get('esas_no', ''),\n",
    "                'karar_no': row.get('kararNo', '') or row.get('karar_no', ''),\n",
    "                'daire': row.get('location', ''),\n",
    "                'tarih': row.get('extractedDates', '') or row.get('dates', ''),\n",
    "                'esas_no_num': row.get('esasNo_num', ''),\n",
    "                'esas_no_tip': row.get('esasNo_tip', ''),\n",
    "                'karar_no_num': row.get('kararNo_num', ''),\n",
    "                'karar_no_tip': row.get('kararNo_tip', ''),\n",
    "                'document_id': row.get('_id', ''),\n",
    "            }\n",
    "            \n",
    "            # Semantic chunking yap\n",
    "            chunks = self.semantic_chunk_text(str(text), metadata)\n",
    "            all_chunks.extend(chunks)\n",
    "            \n",
    "            # Progress gÃ¶ster\n",
    "            if (idx + 1) % 5 == 0:  # Daha sÄ±k progress gÃ¶ster (az veri olduÄŸu iÃ§in)\n",
    "                print(f\"  âœ… Ä°ÅŸlenen satÄ±r: {idx + 1}/{len(df)} (Toplam chunk: {len(all_chunks)})\")\n",
    "        \n",
    "        print(f\"ğŸ§© Toplam {len(all_chunks)} chunk oluÅŸturuldu\")\n",
    "        return all_chunks\n",
    "    \n",
    "    def upload_to_qdrant(self, chunks: List[Dict]):\n",
    "        \"\"\"Chunk'larÄ± Qdrant'a yÃ¼kle\"\"\"\n",
    "        if not chunks:\n",
    "            print(\"âŒ YÃ¼klenecek chunk yok\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸš€ {len(chunks)} chunk Qdrant'a yÃ¼kleniyor...\")\n",
    "        \n",
    "        # Metinleri topla\n",
    "        texts = [chunk['text'] for chunk in chunks]\n",
    "        \n",
    "        # BGE-M3 ile embedding'leri oluÅŸtur\n",
    "        print(\"ğŸ”® BGE-M3 embedding'ler oluÅŸturuluyor...\")\n",
    "        embeddings = self.create_embeddings_bge(texts)\n",
    "        \n",
    "        if len(embeddings) != len(chunks):\n",
    "            print(f\"âŒ Embedding sayÄ±sÄ± uyumsuz: {len(embeddings)} vs {len(chunks)}\")\n",
    "            return\n",
    "        \n",
    "        # Qdrant point'leri hazÄ±rla\n",
    "        points = []\n",
    "        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "            point = PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector=embedding,\n",
    "                payload=chunk\n",
    "            )\n",
    "            points.append(point)\n",
    "        \n",
    "        # Batch halinde yÃ¼kle\n",
    "        batch_size = self.config.BATCH_SIZE\n",
    "        print(f\"ğŸ“¦ {batch_size} batch size ile yÃ¼kleniyor...\")\n",
    "        \n",
    "        for i in range(0, len(points), batch_size):\n",
    "            batch = points[i:i + batch_size]\n",
    "            \n",
    "            try:\n",
    "                self.qdrant_client.upsert(\n",
    "                    collection_name=self.config.COLLECTION_NAME,\n",
    "                    points=batch\n",
    "                )\n",
    "                print(f\"  âœ… Batch yÃ¼klendi: {min(i + batch_size, len(points))}/{len(points)}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Batch yÃ¼kleme hatasÄ±: {e}\")\n",
    "        \n",
    "        print(\"ğŸ‰ YÃ¼kleme tamamlandÄ±!\")\n",
    "    \n",
    "    def search_semantic(self, query: str, limit: int = 10, score_threshold: float = 0.6) -> List[Dict]:\n",
    "        \"\"\"BGE-M3 ile semantic arama yap\"\"\"\n",
    "        print(f\"ğŸ” Arama: '{query}'\")\n",
    "        \n",
    "        try:\n",
    "            # Query'yi BGE-M3 ile vektÃ¶rize et\n",
    "            query_embeddings = self.bge_model.encode([query])\n",
    "            query_vector = query_embeddings['dense_vecs'][0].tolist()\n",
    "            \n",
    "            # Qdrant'ta ara (gÃ¼ncel query_points metodu)\n",
    "            search_results = self.qdrant_client.query_points(\n",
    "                collection_name=self.config.COLLECTION_NAME,\n",
    "                query=query_vector,\n",
    "                limit=limit,\n",
    "                score_threshold=score_threshold\n",
    "            )\n",
    "            \n",
    "            # SonuÃ§larÄ± formatla\n",
    "            results = []\n",
    "            for point in search_results.points:\n",
    "                results.append({\n",
    "                    'score': point.score,\n",
    "                    'payload': point.payload\n",
    "                })\n",
    "            \n",
    "            print(f\"ğŸ“Š {len(results)} sonuÃ§ bulundu\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Arama hatasÄ±: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def advanced_search_with_filters(self, query: str, filters: Dict = None, limit: int = 10, score_threshold: float = 0.6) -> List[Dict]:\n",
    "        \"\"\"Filtreli arama yap\"\"\"\n",
    "        print(f\"ğŸ” Filtreli arama: '{query}' - Filtreler: {filters}\")\n",
    "        \n",
    "        try:\n",
    "            # Query'yi BGE-M3 ile vektÃ¶rize et\n",
    "            query_embeddings = self.bge_model.encode([query])\n",
    "            query_vector = query_embeddings['dense_vecs'][0].tolist()\n",
    "            \n",
    "            # Filter oluÅŸtur\n",
    "            query_filter = None\n",
    "            if filters:\n",
    "                from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "                conditions = []\n",
    "                for key, value in filters.items():\n",
    "                    conditions.append(FieldCondition(key=key, match=MatchValue(value=value)))\n",
    "                query_filter = Filter(must=conditions)\n",
    "            \n",
    "            # Qdrant'ta filtreli arama yap\n",
    "            search_results = self.qdrant_client.query_points(\n",
    "                collection_name=self.config.COLLECTION_NAME,\n",
    "                query=query_vector,\n",
    "                query_filter=query_filter,\n",
    "                limit=limit,\n",
    "                score_threshold=score_threshold\n",
    "            )\n",
    "            \n",
    "            # SonuÃ§larÄ± formatla\n",
    "            results = []\n",
    "            for point in search_results.points:\n",
    "                results.append({\n",
    "                    'score': point.score,\n",
    "                    'payload': point.payload\n",
    "                })\n",
    "            \n",
    "            print(f\"ğŸ“Š {len(results)} filtreli sonuÃ§ bulundu\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Filtreli arama hatasÄ±: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_collection_info(self) -> dict:\n",
    "        \"\"\"Koleksiyon bilgilerini al\"\"\"\n",
    "        try:\n",
    "            info = self.qdrant_client.get_collection(self.config.COLLECTION_NAME)\n",
    "            return {\n",
    "                \"collection_name\": self.config.COLLECTION_NAME,\n",
    "                \"points_count\": info.points_count,\n",
    "                \"vectors_count\": info.vectors_count,\n",
    "                \"status\": info.status,\n",
    "                \"embedding_model\": \"BGE-M3\",\n",
    "                \"embedding_dim\": self.config.EMBEDDING_DIM\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "# Ana Pipeline SÄ±nÄ±fÄ±\n",
    "class YargitayPipeline:\n",
    "    \"\"\"Ana pipeline sÄ±nÄ±fÄ±\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.processor = YargitaySemanticProcessor(config)\n",
    "        self.config = config\n",
    "    \n",
    "    def full_pipeline(self, csv_path: str = None):\n",
    "        \"\"\"Tam pipeline'Ä± Ã§alÄ±ÅŸtÄ±r\"\"\"\n",
    "        csv_path = csv_path or self.config.CSV_FILE\n",
    "        \n",
    "        print(\"ğŸš€ YargÄ±tay BGE-M3 Semantic Pipeline BaÅŸlÄ±yor\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # 1. BGE-M3 modelini test et\n",
    "        embedding_dim = self.processor.test_bge_connection()\n",
    "        if not embedding_dim:\n",
    "            return False\n",
    "        \n",
    "        # 2. Koleksiyon oluÅŸtur\n",
    "        self.processor.create_qdrant_collection(recreate=True)\n",
    "        \n",
    "        # 3. CSV'yi iÅŸle\n",
    "        chunks = self.processor.process_csv_file(csv_path)\n",
    "        if not chunks:\n",
    "            print(\"âŒ Ä°ÅŸlenecek chunk bulunamadÄ±\")\n",
    "            return False\n",
    "        \n",
    "        # 4. Qdrant'a yÃ¼kle\n",
    "        self.processor.upload_to_qdrant(chunks)\n",
    "        \n",
    "        # 5. Bilgileri gÃ¶ster\n",
    "        info = self.processor.get_collection_info()\n",
    "        print(\"\\nğŸ“Š Koleksiyon Bilgileri:\")\n",
    "        print(json.dumps(info, indent=2, ensure_ascii=False))\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def interactive_search(self):\n",
    "        \"\"\"Ä°nteraktif arama arayÃ¼zÃ¼\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ğŸ›ï¸ YARGITAY BGE-M3 SEMANTÄ°K ARAMA SÄ°STEMÄ°\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        while True:\n",
    "            print(\"\\nğŸ” Arama SeÃ§enekleri:\")\n",
    "            print(\"1. Basit arama\")\n",
    "            print(\"2. Filtreli arama\")\n",
    "            print(\"3. Ana menÃ¼ye dÃ¶n\")\n",
    "            \n",
    "            search_choice = input(\"SeÃ§iminiz (1-3): \")\n",
    "            \n",
    "            if search_choice == \"3\":\n",
    "                break\n",
    "            elif search_choice not in [\"1\", \"2\"]:\n",
    "                print(\"âŒ GeÃ§ersiz seÃ§im!\")\n",
    "                continue\n",
    "            \n",
    "            query = input(\"\\nğŸ” Arama metni (Ã§Ä±kmak iÃ§in 'q'): \")\n",
    "            if query.lower() in ['q', 'quit', 'exit']:\n",
    "                break\n",
    "            \n",
    "            if not query.strip():\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                limit = int(input(\"ğŸ“Š KaÃ§ sonuÃ§? (varsayÄ±lan 5): \") or \"5\")\n",
    "                threshold = float(input(\"ğŸ¯ Minimum benzerlik skoru? (varsayÄ±lan 0.6): \") or \"0.6\")\n",
    "            except:\n",
    "                limit = 5\n",
    "                threshold = 0.6\n",
    "            \n",
    "            # Arama tipini belirle\n",
    "            if search_choice == \"1\":\n",
    "                results = self.processor.search_semantic(query, limit=limit, score_threshold=threshold)\n",
    "            else:\n",
    "                # Filtreli arama\n",
    "                print(\"\\nğŸ”§ Filtre SeÃ§enekleri (boÅŸ bÄ±rakabilirsiniz):\")\n",
    "                daire_filter = input(\"Daire filtresi (Ã¶rn: '6. Hukuk Dairesi'): \").strip()\n",
    "                \n",
    "                filters = {}\n",
    "                if daire_filter:\n",
    "                    filters['daire'] = daire_filter\n",
    "                \n",
    "                results = self.processor.advanced_search_with_filters(\n",
    "                    query, filters=filters if filters else None, \n",
    "                    limit=limit, score_threshold=threshold\n",
    "                )\n",
    "            \n",
    "            if not results:\n",
    "                print(\"âŒ SonuÃ§ bulunamadÄ±\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nğŸ“‹ {len(results)} sonuÃ§ bulundu:\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            for i, result in enumerate(results, 1):\n",
    "                payload = result['payload']\n",
    "                print(f\"\\n{i}. ğŸ“„ BGE-M3 Benzerlik Skoru: {result['score']:.3f}\")\n",
    "                print(f\"   âš–ï¸ Esas No: {payload.get('esas_no', 'N/A')}\")\n",
    "                print(f\"   ğŸ“‹ Karar No: {payload.get('karar_no', 'N/A')}\")\n",
    "                print(f\"   ğŸ›ï¸ Daire: {payload.get('daire', 'N/A')}\")\n",
    "                print(f\"   ğŸ“… Tarih: {payload.get('tarih', 'N/A')}\")\n",
    "                print(f\"   ğŸ”¤ Token: {payload.get('token_count', 'N/A')}\")\n",
    "                print(f\"   ğŸ“ Metin Ã–nizleme:\")\n",
    "                \n",
    "                text = payload.get('text', '')\n",
    "                preview = text[:300] + \"...\" if len(text) > 300 else text\n",
    "                print(f\"      {preview}\")\n",
    "                print(\"-\" * 60)\n",
    "\n",
    "# KullanÄ±m Ã¶rneÄŸi ve main fonksiyon\n",
    "def main():\n",
    "    \"\"\"Ana fonksiyon\"\"\"\n",
    "    \n",
    "    # KonfigÃ¼rasyon\n",
    "    config = Config(\n",
    "        CSV_FILE=\"/home/yapayzeka/ahsen_bulbul/data/cleaned10chunk.csv\",\n",
    "        TOKEN_SIZE=512,  # Chunk boyutu\n",
    "        QDRANT_URL=\"http://localhost:6333\",\n",
    "        COLLECTION_NAME=\"bge_m3_chunks\",\n",
    "        EMBEDDING_DIM=1024,\n",
    "        BATCH_SIZE=16,  # GPU memory'ye gÃ¶re ayarlayÄ±n\n",
    "        USE_FP16=True,\n",
    "        DEVICE=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "    \n",
    "    # Pipeline oluÅŸtur\n",
    "    pipeline = YargitayPipeline(config)\n",
    "    \n",
    "    # MenÃ¼ gÃ¶ster\n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ğŸ›ï¸ YARGITAY BGE-M3 SEMANTÄ°K CHUNK SÄ°STEMÄ°\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"1. Tam pipeline Ã§alÄ±ÅŸtÄ±r (CSV â†’ Semantic Chunks â†’ BGE-M3 â†’ Qdrant)\")\n",
    "        print(\"2. Ä°nteraktif arama yap\")\n",
    "        print(\"3. Koleksiyon bilgilerini gÃ¶ster\")\n",
    "        print(\"4. Ã‡Ä±kÄ±ÅŸ\")\n",
    "        \n",
    "        choice = input(\"\\nSeÃ§iminiz (1-4): \")\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            csv_path = input(f\"CSV dosya yolu (Enter: {config.CSV_FILE}): \").strip()\n",
    "            if not csv_path:\n",
    "                csv_path = config.CSV_FILE\n",
    "            \n",
    "            success = pipeline.full_pipeline(csv_path)\n",
    "            if success:\n",
    "                print(\"âœ… BGE-M3 Pipeline baÅŸarÄ±yla tamamlandÄ±!\")\n",
    "            else:\n",
    "                print(\"âŒ Pipeline hatasÄ±!\")\n",
    "        \n",
    "        elif choice == \"2\":\n",
    "            pipeline.interactive_search()\n",
    "        \n",
    "        elif choice == \"3\":\n",
    "            info = pipeline.processor.get_collection_info()\n",
    "            print(\"\\nğŸ“Š Koleksiyon Bilgileri:\")\n",
    "            print(json.dumps(info, indent=2, ensure_ascii=False))\n",
    "        \n",
    "        elif choice == \"4\":\n",
    "            print(\"ğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"âŒ GeÃ§ersiz seÃ§im!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # BGE-M3 kurulumu kontrolÃ¼\n",
    "    try:\n",
    "        from FlagEmbedding import BGEM3FlagModel\n",
    "        print(\"âœ… FlagEmbedding kÃ¼tÃ¼phanesi yÃ¼klÃ¼\")\n",
    "    except ImportError:\n",
    "        print(\"âŒ FlagEmbedding kÃ¼tÃ¼phanesi bulunamadÄ±!\")\n",
    "        print(\"Kurulum iÃ§in: pip install FlagEmbedding\")\n",
    "        exit(1)\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahsen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
