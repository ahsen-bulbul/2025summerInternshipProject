{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yapayzeka/ahsen_bulbul/ahsen/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "✅ FlagEmbedding yüklü\n",
      "🔮 BGE-M3 yükleniyor: BAAI/bge-m3 (device=cuda)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 280243.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hazır - Cihaz: NVIDIA RTX A6000\n",
      "\n",
      "============================================================\n",
      "🏛️ YARGITAY BGE-M3 SEMANTİK SİSTEM\n",
      "============================================================\n",
      "1) Tam pipeline çalıştır (CSV -> chunks -> embed -> qdrant)\n",
      "2) İnteraktif arama\n",
      "3) Koleksiyon bilgilerini göster\n",
      "4) Çıkış\n",
      "\n",
      "🔎 İnteraktif arama başlatıldı\n",
      "\n",
      "1) Basit arama\n",
      "2) Filtreli arama\n",
      "3) Ana menü\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Query vector boyutu: 512 (hedef: 512)\n",
      "📊 5 sonuç bulundu\n",
      "\n",
      "📋 5 sonuç:\n",
      "\n",
      "1. Skor: 0.0932\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: kat karşılığı inşaat sözleşmesi gereğince arsa sahibine verilmesi kararlaştırılan (noter kura çekimi ile müvekkiline isabet etmiş bulunan) bağımsız bölüm olduğuna göre artık yüklenicinin edimini yerine getirip getirmediğine bakılmaksızın arsa sahibinin sözleşmeyi ayakta tutarak tapu iptali ve tescil...\n",
      "------------------------------------------------------------\n",
      "\n",
      "2. Skor: 0.0901\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: üzerinde yapacağı küçük bir araştırma ile yükleniciye tapuda pay devreden taşınmaz paydaşlarının sözleşme ile vaat edilen ve 2012 yılında çekilen kur’a ile adlarına isabet eden bağımsız bölümleri halen teslim alamadıklarını, sonuç olarak yüklenicinin arsa payı devralmak suretiyle inşaatı yapmak üzer...\n",
      "------------------------------------------------------------\n",
      "\n",
      "3. Skor: 0.0857\n",
      "   Esas No: 2023/576 E. | Karar No: 2024/399 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 30.01.2024,15.07.2017,24.04.2013,24.01.2023,30.01.2024\n",
      "   Metin: arasında imzalanan 15.07.2017 tarihli adi yazılı gayrimenkul satış vaadi sözleşmesi ile davacının 236 ada 1 parselde kain tip 18 villa niteliğindeki 286 no.lu bağımsız bölümü satın aldığını, satış bedelinin tamamen ödenmiş olduğunu ve taşınmazın Mart 2018 tarihinde fiilen teslim edildiğini, fakat çe...\n",
      "------------------------------------------------------------\n",
      "\n",
      "4. Skor: 0.0831\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: Bölge Adliye Mahkemesinin yukarıda belirtilen kararına karşı süresi içinde davalı ... vekili temyiz isteminde bulunmuştur. 2. Dairemizin 17.02.2022 tarihli ve 2021/2532 Esas, 2022/901 Karar sayılı ilamıyla; \"Mahkemece davalı ... hakkındaki tapu iptali ve tescil kararı davalı yüklenici şirketin arsa ...\n",
      "------------------------------------------------------------\n",
      "\n",
      "5. Skor: 0.0827\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: arasında arsa payı karşılığı inşaat sözleşmesi imzalandığını, sözleşme uyarınca arsa sahibi davacıya ait 2 ve 3 no.lu parsellerde bulunan payların davacı yüklenici şirkete devri karşılığı, yüklenici şirketin arsaya yapacağı binalardan, noter huzurunda çekilecek kura sonucu belirlenecek bir adet dair...\n",
      "------------------------------------------------------------\n",
      "\n",
      "1) Basit arama\n",
      "2) Filtreli arama\n",
      "3) Ana menü\n",
      "📊 0 filtreli sonuç bulundu\n",
      "❌ Sonuç bulunamadı\n",
      "\n",
      "1) Basit arama\n",
      "2) Filtreli arama\n",
      "3) Ana menü\n",
      "🔍 Query vector boyutu: 512 (hedef: 512)\n",
      "📊 5 sonuç bulundu\n",
      "\n",
      "📋 5 sonuç:\n",
      "\n",
      "1. Skor: 0.1077\n",
      "   Esas No: 2023/576 E. | Karar No: 2024/399 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 30.01.2024,15.07.2017,24.04.2013,24.01.2023,30.01.2024\n",
      "   Metin: arasında imzalanan 15.07.2017 tarihli adi yazılı gayrimenkul satış vaadi sözleşmesi ile davacının 236 ada 1 parselde kain tip 18 villa niteliğindeki 286 no.lu bağımsız bölümü satın aldığını, satış bedelinin tamamen ödenmiş olduğunu ve taşınmazın Mart 2018 tarihinde fiilen teslim edildiğini, fakat çe...\n",
      "------------------------------------------------------------\n",
      "\n",
      "2. Skor: 0.1054\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: kat karşılığı inşaat sözleşmesi gereğince arsa sahibine verilmesi kararlaştırılan (noter kura çekimi ile müvekkiline isabet etmiş bulunan) bağımsız bölüm olduğuna göre artık yüklenicinin edimini yerine getirip getirmediğine bakılmaksızın arsa sahibinin sözleşmeyi ayakta tutarak tapu iptali ve tescil...\n",
      "------------------------------------------------------------\n",
      "\n",
      "3. Skor: 0.1003\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: arasında arsa payı karşılığı inşaat sözleşmesi imzalandığını, sözleşme uyarınca arsa sahibi davacıya ait 2 ve 3 no.lu parsellerde bulunan payların davacı yüklenici şirkete devri karşılığı, yüklenici şirketin arsaya yapacağı binalardan, noter huzurunda çekilecek kura sonucu belirlenecek bir adet dair...\n",
      "------------------------------------------------------------\n",
      "\n",
      "4. Skor: 0.0998\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: üzerinde yapacağı küçük bir araştırma ile yükleniciye tapuda pay devreden taşınmaz paydaşlarının sözleşme ile vaat edilen ve 2012 yılında çekilen kur’a ile adlarına isabet eden bağımsız bölümleri halen teslim alamadıklarını, sonuç olarak yüklenicinin arsa payı devralmak suretiyle inşaatı yapmak üzer...\n",
      "------------------------------------------------------------\n",
      "\n",
      "5. Skor: 0.0951\n",
      "   Esas No: 2023/4462 E. | Karar No: 2024/493 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 10.04.1992,05.02.2024\n",
      "   Metin: sözleşmesinin feshedildiği tarihteki giydirilmiş ücret üzerinden hesaplanmakta olup bu kıdem tazminatının tamamından işçiyi çalıştırdıkları dönemle orantılı olarak yükleniciler işverene karşı sorumludurlar. Yıllık izinler kullanılmadığı taktirde ... sözleşmesinin feshi ile ücrete dönüşmektedir. Sözl...\n",
      "------------------------------------------------------------\n",
      "\n",
      "1) Basit arama\n",
      "2) Filtreli arama\n",
      "3) Ana menü\n",
      "❌ Geçersiz seçim\n",
      "\n",
      "1) Basit arama\n",
      "2) Filtreli arama\n",
      "3) Ana menü\n",
      "🔍 Query vector boyutu: 512 (hedef: 512)\n",
      "📊 5 sonuç bulundu\n",
      "\n",
      "📋 5 sonuç:\n",
      "\n",
      "1. Skor: 0.1141\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: üzerinde yapacağı küçük bir araştırma ile yükleniciye tapuda pay devreden taşınmaz paydaşlarının sözleşme ile vaat edilen ve 2012 yılında çekilen kur’a ile adlarına isabet eden bağımsız bölümleri halen teslim alamadıklarını, sonuç olarak yüklenicinin arsa payı devralmak suretiyle inşaatı yapmak üzer...\n",
      "------------------------------------------------------------\n",
      "\n",
      "2. Skor: 0.1056\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: arasında arsa payı karşılığı inşaat sözleşmesi imzalandığını, sözleşme uyarınca arsa sahibi davacıya ait 2 ve 3 no.lu parsellerde bulunan payların davacı yüklenici şirkete devri karşılığı, yüklenici şirketin arsaya yapacağı binalardan, noter huzurunda çekilecek kura sonucu belirlenecek bir adet dair...\n",
      "------------------------------------------------------------\n",
      "\n",
      "3. Skor: 0.0955\n",
      "   Esas No: 2023/4462 E. | Karar No: 2024/493 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 10.04.1992,05.02.2024\n",
      "   Metin: III. MAHKEME KARARI Mahkemenin yukarıda tarih ve sayısı belirtilen kararıyla davalılardan ... Hizm. Tic. Ltd. Şti. yönünden dava dışı işçinin hizmet cetveli ve işe giriş bildirgeleri incelendiğinde bu şirket bünyesinde ve belirtilen dönemde bir çalışmasının bulunmadığı gerekçesiyle bu davalı şirket ...\n",
      "------------------------------------------------------------\n",
      "\n",
      "4. Skor: 0.0949\n",
      "   Esas No: 2023/576 E. | Karar No: 2024/399 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 30.01.2024,15.07.2017,24.04.2013,24.01.2023,30.01.2024\n",
      "   Metin: arasında imzalanan 15.07.2017 tarihli adi yazılı gayrimenkul satış vaadi sözleşmesi ile davacının 236 ada 1 parselde kain tip 18 villa niteliğindeki 286 no.lu bağımsız bölümü satın aldığını, satış bedelinin tamamen ödenmiş olduğunu ve taşınmazın Mart 2018 tarihinde fiilen teslim edildiğini, fakat çe...\n",
      "------------------------------------------------------------\n",
      "\n",
      "5. Skor: 0.0928\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: Bölge Adliye Mahkemesinin yukarıda belirtilen kararına karşı süresi içinde davalı ... vekili temyiz isteminde bulunmuştur. 2. Dairemizin 17.02.2022 tarihli ve 2021/2532 Esas, 2022/901 Karar sayılı ilamıyla; \"Mahkemece davalı ... hakkındaki tapu iptali ve tescil kararı davalı yüklenici şirketin arsa ...\n",
      "------------------------------------------------------------\n",
      "\n",
      "1) Basit arama\n",
      "2) Filtreli arama\n",
      "3) Ana menü\n",
      "\n",
      "============================================================\n",
      "🏛️ YARGITAY BGE-M3 SEMANTİK SİSTEM\n",
      "============================================================\n",
      "1) Tam pipeline çalıştır (CSV -> chunks -> embed -> qdrant)\n",
      "2) İnteraktif arama\n",
      "3) Koleksiyon bilgilerini göster\n",
      "4) Çıkış\n",
      "👋 Görüşürüz\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "# SemChunk + BGE-M3 + Qdrant Entegrasyon (Normalize edilmiş, reducer uyumlu, query_points kullanıyor)\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import semchunk\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n",
    "import uuid\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "print(load_dotenv(\"/home/yapayzeka/ahsen_bulbul/qdrant/.env\"))\n",
    "\n",
    "# -------------------------\n",
    "# Helper: normalize tensor rows (L2)\n",
    "# -------------------------\n",
    "def l2_normalize_tensor(t: torch.Tensor, eps: float = 1e-10) -> torch.Tensor:\n",
    "    # t: (N, D)\n",
    "    norm = torch.norm(t, dim=1, keepdim=True).clamp(min=eps)\n",
    "    return t / norm\n",
    "\n",
    "# Embed reducer (1024 -> 512)\n",
    "class EmbedReducer(nn.Module):\n",
    "    def __init__(self, input_dim: int = 1024, output_dim: int = 512):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(x)\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    BGE_MODEL_NAME: str = \"BAAI/bge-m3\"\n",
    "    USE_FP16: bool = True\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    TOKEN_SIZE: int = 512\n",
    "    ENCODING_NAME: str = \"cl100k_base\"\n",
    "    QDRANT_URL: str = \"http://localhost:6333\"\n",
    "    COLLECTION_NAME: str = \"yargitay_bge_m3_chunks\"\n",
    "    EMBEDDING_DIM: int = 512\n",
    "    CSV_FILE: str = \"/home/yapayzeka/ahsen_bulbul/data/cleaned10chunk.csv\"\n",
    "    BATCH_SIZE: int = 100\n",
    "    DB_BATCH: int = 256\n",
    "\n",
    "# -------------------------\n",
    "# Processor\n",
    "# -------------------------\n",
    "class YargitaySemanticProcessor:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "\n",
    "        # Encoding & chunker\n",
    "        self.encoding = tiktoken.get_encoding(config.ENCODING_NAME)\n",
    "        self.chunker = semchunk.chunkerify(self.encoding, config.TOKEN_SIZE)\n",
    "\n",
    "        # Model & reducer\n",
    "        print(f\"🔮 BGE-M3 yükleniyor: {config.BGE_MODEL_NAME} (device={config.DEVICE})\")\n",
    "        self.bge_model = BGEM3FlagModel(config.BGE_MODEL_NAME, use_fp16=config.USE_FP16, device=config.DEVICE)\n",
    "        self.reducer = EmbedReducer(input_dim=1024, output_dim=self.config.EMBEDDING_DIM).to(config.DEVICE)\n",
    "\n",
    "        # Qdrant\n",
    "        self.qdrant_client = QdrantClient(url=config.QDRANT_URL)\n",
    "\n",
    "        device_name = torch.cuda.get_device_name() if torch.cuda.is_available() else \"CPU\"\n",
    "        print(f\"✅ Hazır - Cihaz: {device_name}\")\n",
    "\n",
    "    # Test connection & print dense dim\n",
    "    def test_bge_connection(self):\n",
    "        try:\n",
    "            test_text = [\"Yargıtay 6. Hukuk Dairesi'nin ihtiyati tedbir kararı\"]\n",
    "            emb_res = self.bge_model.encode(test_text)\n",
    "            dense = emb_res['dense_vecs'][0]\n",
    "            print(f\"✅ BGE-M3 test başarılı - Dense embedding boyutu: {len(dense)}\")\n",
    "            print(f\"🔍 Sparse embedding mevcut: {'colbert_vecs' in emb_res}\")\n",
    "            return len(dense)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ BGE-M3 bağlantı hatası: {e}\")\n",
    "            return None\n",
    "\n",
    "    def create_qdrant_collection(self, recreate: bool = False):\n",
    "        collection_name = self.config.COLLECTION_NAME\n",
    "        if recreate:\n",
    "            try:\n",
    "                self.qdrant_client.delete_collection(collection_name)\n",
    "                print(f\"🗑️ Eski koleksiyon silindi: {collection_name}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            existing = [c.name for c in self.qdrant_client.get_collections().collections]\n",
    "            if collection_name not in existing:\n",
    "                self.qdrant_client.create_collection(\n",
    "                    collection_name=collection_name,\n",
    "                    vectors_config=VectorParams(size=self.config.EMBEDDING_DIM, distance=Distance.COSINE)\n",
    "                )\n",
    "                print(f\"✅ Koleksiyon oluşturuldu: {collection_name} (dim={self.config.EMBEDDING_DIM})\")\n",
    "            else:\n",
    "                print(f\"ℹ️ Koleksiyon zaten var: {collection_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Koleksiyon oluşturma hatası: {e}\")\n",
    "            raise\n",
    "\n",
    "    def semantic_chunk_text(self, text: str, metadata: dict = None) -> List[Dict]:\n",
    "        if not text or not text.strip():\n",
    "            return []\n",
    "        try:\n",
    "            chunks = self.chunker(text)\n",
    "            result = []\n",
    "            for i, c in enumerate(chunks):\n",
    "                if c.strip():\n",
    "                    cd = {\n",
    "                        'chunk_id': i,\n",
    "                        'text': c.strip(),\n",
    "                        'token_count': len(self.encoding.encode(c)),\n",
    "                        'char_count': len(c)\n",
    "                    }\n",
    "                    if metadata:\n",
    "                        cd.update(metadata)\n",
    "                    result.append(cd)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Chunking hatası: {e}\")\n",
    "            return []\n",
    "\n",
    "    def create_embeddings_bge(self, texts: List[str], batch_size: int = None) -> List[List[float]]:\n",
    "        batch_size = batch_size or self.config.BATCH_SIZE\n",
    "        all_embeddings: List[List[float]] = []\n",
    "        total = len(texts)\n",
    "        print(f\"🔮 BGE-M3 ile {total} metin işleniyor (batch_size={batch_size})...\")\n",
    "\n",
    "        for i in range(0, total, batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            try:\n",
    "                # 1) embed (BGE-M3) -> dense (1024)\n",
    "                emb_res = self.bge_model.encode(batch_texts)\n",
    "                if isinstance(emb_res, dict) and 'dense_vecs' in emb_res:\n",
    "                    dense = emb_res['dense_vecs']\n",
    "                else:\n",
    "                    dense = emb_res\n",
    "\n",
    "                # 2) to tensor, device\n",
    "                if not isinstance(dense, torch.Tensor):\n",
    "                    dense_t = torch.tensor(dense, dtype=torch.float32, device=self.config.DEVICE)\n",
    "                else:\n",
    "                    dense_t = dense.to(self.config.DEVICE)\n",
    "\n",
    "                # 3) reducer -> 512\n",
    "                with torch.no_grad():\n",
    "                    reduced = self.reducer(dense_t)\n",
    "\n",
    "                # 4) normalize L2 (important for cosine)\n",
    "                reduced = l2_normalize_tensor(reduced)\n",
    "\n",
    "                # 5) append as python lists (cpu)\n",
    "                all_embeddings.extend([v.cpu().tolist() for v in reduced])\n",
    "\n",
    "                print(f\"  📊 Batch işlendi: {i + len(batch_texts)}/{total}\")\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ BGE-M3 Embedding hatası (batch {i//batch_size + 1}): {e}\")\n",
    "                # fallback zero vectors\n",
    "                all_embeddings.extend([[0.0] * self.config.EMBEDDING_DIM for _ in batch_texts])\n",
    "\n",
    "        return all_embeddings\n",
    "\n",
    "    def process_csv_file(self, csv_path: str) -> List[Dict]:\n",
    "        print(f\"📄 CSV okunuyor: {csv_path}\")\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            print(f\"📊 {len(df)} satır yüklendi\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ CSV okuma hatası: {e}\")\n",
    "            return []\n",
    "\n",
    "        text_column = next((c for c in ['rawText', 'chunk_text', 'text', 'content', 'metin'] if c in df.columns), None)\n",
    "        if not text_column:\n",
    "            print(\"❌ Ana metin sütunu bulunamadı\")\n",
    "            return []\n",
    "\n",
    "        all_chunks = []\n",
    "        for idx, row in df.iterrows():\n",
    "            text = row.get(text_column, '')\n",
    "            if not text or pd.isna(text):\n",
    "                continue\n",
    "            meta = {\n",
    "                'original_index': idx,\n",
    "                'esas_no': row.get('esasNo', ''),\n",
    "                'karar_no': row.get('kararNo', ''),\n",
    "                'daire': row.get('location', ''),\n",
    "                'tarih': row.get('extractedDates', ''),\n",
    "                'document_id': row.get('_id', ''),\n",
    "            }\n",
    "            chunks = self.semantic_chunk_text(str(text), meta)\n",
    "            all_chunks.extend(chunks)\n",
    "            if (idx + 1) % 5 == 0:\n",
    "                print(f\"  ✅ İşlenen satır: {idx + 1}/{len(df)} (Toplam chunk: {len(all_chunks)})\")\n",
    "\n",
    "        print(f\"🧩 Toplam {len(all_chunks)} chunk oluşturuldu\")\n",
    "        return all_chunks\n",
    "\n",
    "    def upload_to_qdrant(self, chunks: List[Dict]):\n",
    "        if not chunks:\n",
    "            print(\"❌ Yüklenecek chunk yok\")\n",
    "            return\n",
    "\n",
    "        print(f\"🚀 {len(chunks)} chunk Qdrant'a yükleniyor...\")\n",
    "        texts = [c['text'] for c in chunks]\n",
    "        embeddings = self.create_embeddings_bge(texts)\n",
    "\n",
    "        if len(embeddings) != len(chunks):\n",
    "            print(f\"❌ Embedding sayısı uyumsuz: {len(embeddings)} vs {len(chunks)}\")\n",
    "            return\n",
    "\n",
    "        points = []\n",
    "        for chunk, emb in zip(chunks, embeddings):\n",
    "            points.append(PointStruct(id=str(uuid.uuid4()), vector=emb, payload=chunk))\n",
    "\n",
    "        batch = self.config.DB_BATCH\n",
    "        for i in range(0, len(points), batch):\n",
    "            try:\n",
    "                self.qdrant_client.upsert(collection_name=self.config.COLLECTION_NAME, points=points[i:i+batch])\n",
    "                print(f\"  ✅ Batch yüklendi: {min(i+batch, len(points))}/{len(points)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Batch yükleme hatası: {e}\")\n",
    "\n",
    "        print(\"🎉 Yükleme tamamlandı!\")\n",
    "\n",
    "    # ---------- SEARCH (query_points + reducer + normalize) ----------\n",
    "    def search_semantic(self, query: str, limit: int = 10, score_threshold: float = None) -> List[Dict]:\n",
    "        try:\n",
    "            emb_res = self.bge_model.encode([query])\n",
    "            q_dense = emb_res['dense_vecs'] if isinstance(emb_res, dict) and 'dense_vecs' in emb_res else emb_res\n",
    "\n",
    "            if not isinstance(q_dense, torch.Tensor):\n",
    "                q_t = torch.tensor(q_dense, dtype=torch.float32, device=self.config.DEVICE)\n",
    "            else:\n",
    "                q_t = q_dense.to(self.config.DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                reduced_q = self.reducer(q_t)\n",
    "                reduced_q = l2_normalize_tensor(reduced_q)\n",
    "\n",
    "            query_vector = reduced_q[0].cpu().tolist()\n",
    "            print(f\"🔍 Query vector boyutu: {len(query_vector)} (hedef: {self.config.EMBEDDING_DIM})\")\n",
    "\n",
    "            # use query_points (recommended)\n",
    "            qr = self.qdrant_client.query_points(\n",
    "                collection_name=self.config.COLLECTION_NAME,\n",
    "                query=query_vector,\n",
    "                limit=limit,\n",
    "                score_threshold=score_threshold\n",
    "            )\n",
    "\n",
    "            results = [{'score': p.score, 'payload': p.payload} for p in qr.points]\n",
    "            print(f\"📊 {len(results)} sonuç bulundu\")\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Arama hatası: {e}\")\n",
    "            return []\n",
    "\n",
    "    def advanced_search_with_filters(self, query: str, filters: Dict = None, limit: int = 10, score_threshold: float = None) -> List[Dict]:\n",
    "        try:\n",
    "            # prepare reduced + normalized query vector same as above\n",
    "            emb_res = self.bge_model.encode([query])\n",
    "            q_dense = emb_res['dense_vecs'] if isinstance(emb_res, dict) and 'dense_vecs' in emb_res else emb_res\n",
    "            if not isinstance(q_dense, torch.Tensor):\n",
    "                q_t = torch.tensor(q_dense, dtype=torch.float32, device=self.config.DEVICE)\n",
    "            else:\n",
    "                q_t = q_dense.to(self.config.DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                reduced_q = self.reducer(q_t)\n",
    "                reduced_q = l2_normalize_tensor(reduced_q)\n",
    "\n",
    "            query_vector = reduced_q[0].cpu().tolist()\n",
    "\n",
    "            query_filter = None\n",
    "            if filters:\n",
    "                from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "                conditions = [FieldCondition(key=k, match=MatchValue(value=v)) for k, v in filters.items()]\n",
    "                query_filter = Filter(must=conditions)\n",
    "\n",
    "            qr = self.qdrant_client.query_points(\n",
    "                collection_name=self.config.COLLECTION_NAME,\n",
    "                query=query_vector,\n",
    "                query_filter=query_filter,\n",
    "                limit=limit,\n",
    "                score_threshold=score_threshold\n",
    "            )\n",
    "\n",
    "            results = [{'score': p.score, 'payload': p.payload} for p in qr.points]\n",
    "            print(f\"📊 {len(results)} filtreli sonuç bulundu\")\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Filtreli arama hatası: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_collection_info(self) -> dict:\n",
    "        try:\n",
    "            info = self.qdrant_client.get_collection(self.config.COLLECTION_NAME)\n",
    "            return {\n",
    "                \"collection_name\": self.config.COLLECTION_NAME,\n",
    "                \"points_count\": info.points_count,\n",
    "                \"vectors_count\": info.vectors_count,\n",
    "                \"status\": info.status,\n",
    "                \"embedding_model\": \"BGE-M3\",\n",
    "                \"embedding_dim\": self.config.EMBEDDING_DIM\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "# -------------------------\n",
    "# Pipeline + main\n",
    "# -------------------------\n",
    "class YargitayPipeline:\n",
    "    def __init__(self, config: Config):\n",
    "        self.processor = YargitaySemanticProcessor(config)\n",
    "        self.config = config\n",
    "\n",
    "    def full_pipeline(self, csv_path: str = None):\n",
    "        csv_path = csv_path or self.config.CSV_FILE\n",
    "        print(\"🚀 Full pipeline başlıyor\")\n",
    "        emb_dim = self.processor.test_bge_connection()\n",
    "        if not emb_dim:\n",
    "            return False\n",
    "        # recreate collection to ensure clean 512-dim index\n",
    "        self.processor.create_qdrant_collection(recreate=True)\n",
    "        chunks = self.processor.process_csv_file(csv_path)\n",
    "        if not chunks:\n",
    "            print(\"❌ Chunk bulunamadı\")\n",
    "            return False\n",
    "        self.processor.upload_to_qdrant(chunks)\n",
    "        info = self.processor.get_collection_info()\n",
    "        print(\"\\n📊 Koleksiyon Bilgileri:\")\n",
    "        print(json.dumps(info, indent=2, ensure_ascii=False))\n",
    "        return True\n",
    "\n",
    "    def interactive_search(self):\n",
    "        print(\"\\n🔎 İnteraktif arama başlatıldı\")\n",
    "        while True:\n",
    "            print(\"\\n1) Basit arama\\n2) Filtreli arama\\n3) Ana menü\")\n",
    "            ch = input(\"Seçiminiz (1-3): \").strip()\n",
    "            if ch == \"3\":\n",
    "                break\n",
    "            if ch not in {\"1\", \"2\"}:\n",
    "                print(\"❌ Geçersiz seçim\")\n",
    "                continue\n",
    "            q = input(\"🔍 Arama metni (çıkmak için 'q'): \").strip()\n",
    "            if q.lower() in {'q', 'quit', 'exit'}:\n",
    "                break\n",
    "            if not q:\n",
    "                continue\n",
    "            try:\n",
    "                limit = int(input(\"Kaç sonuç? (default 5): \") or 5)\n",
    "            except:\n",
    "                limit = 5\n",
    "\n",
    "            if ch == \"1\":\n",
    "                # try with low threshold first for debugging\n",
    "                results = self.processor.search_semantic(q, limit=limit, score_threshold=None)\n",
    "            else:\n",
    "                daire = input(\"Daire filtresi (örn: '6.HukukDairesi', boş = none): \").strip()\n",
    "                filters = {'daire': daire} if daire else None\n",
    "                results = self.processor.advanced_search_with_filters(q, filters=filters, limit=limit, score_threshold=None)\n",
    "\n",
    "            if not results:\n",
    "                print(\"❌ Sonuç bulunamadı\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n📋 {len(results)} sonuç:\")\n",
    "            for i, r in enumerate(results, 1):\n",
    "                p = r['payload']\n",
    "                print(f\"\\n{i}. Skor: {r['score']:.4f}\")\n",
    "                print(f\"   Esas No: {p.get('esas_no','N/A')} | Karar No: {p.get('karar_no','N/A')}\")\n",
    "                print(f\"   Daire: {p.get('daire','N/A')} | Tarih: {p.get('tarih','N/A')}\")\n",
    "                text_preview = (p.get('text','')[:300] + '...') if len(p.get('text','')) > 300 else p.get('text','')\n",
    "                print(f\"   Metin: {text_preview}\")\n",
    "                print(\"-\"*60)\n",
    "\n",
    "def main():\n",
    "    config = Config(\n",
    "        CSV_FILE=\"/home/yapayzeka/ahsen_bulbul/data/cleaned10chunk.csv\",\n",
    "        TOKEN_SIZE=512,\n",
    "        QDRANT_URL=\"http://localhost:6333\",\n",
    "        COLLECTION_NAME=\"bge_m3_chunks\",\n",
    "        EMBEDDING_DIM=512,\n",
    "        BATCH_SIZE=100\n",
    "    )\n",
    "\n",
    "    pipeline = YargitayPipeline(config)\n",
    "\n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"🏛️ YARGITAY BGE-M3 SEMANTİK SİSTEM\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"1) Tam pipeline çalıştır (CSV -> chunks -> embed -> qdrant)\")\n",
    "        print(\"2) İnteraktif arama\")\n",
    "        print(\"3) Koleksiyon bilgilerini göster\")\n",
    "        print(\"4) Çıkış\")\n",
    "        choice = input(\"Seçiminiz (1-4): \").strip()\n",
    "        if choice == \"1\":\n",
    "            csv_path = input(f\"CSV yolu (enter ile default: {config.CSV_FILE}): \").strip() or config.CSV_FILE\n",
    "            ok = pipeline.full_pipeline(csv_path)\n",
    "            print(\"✅ Tamamlandı\" if ok else \"❌ Hata çıktı\")\n",
    "        elif choice == \"2\":\n",
    "            pipeline.interactive_search()\n",
    "        elif choice == \"3\":\n",
    "            info = pipeline.processor.get_collection_info()\n",
    "            print(json.dumps(info, indent=2, ensure_ascii=False))\n",
    "        elif choice == \"4\":\n",
    "            print(\"👋 Görüşürüz\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"❌ Geçersiz seçim\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        from FlagEmbedding import BGEM3FlagModel\n",
    "        print(\"✅ FlagEmbedding yüklü\")\n",
    "    except ImportError:\n",
    "        print(\"❌ FlagEmbedding bulunamadı — pip install FlagEmbedding\")\n",
    "        raise SystemExit(1)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahsen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
