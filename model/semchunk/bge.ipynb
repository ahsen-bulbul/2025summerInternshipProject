{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "‚úÖ FlagEmbedding y√ºkl√º\n",
      "üîÆ BGE-M3 y√ºkleniyor: BAAI/bge-m3 (device=cuda)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 78692.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ôªÔ∏è Reducer aƒüƒ±rlƒ±klarƒ± y√ºklendi\n",
      "‚úÖ Hazƒ±r - Cihaz: NVIDIA RTX A6000\n",
      "\n",
      "============================================================\n",
      "üèõÔ∏è YARGITAY BGE-M3 SEMANTƒ∞K Sƒ∞STEM\n",
      "============================================================\n",
      "1) Tam pipeline √ßalƒ±≈ütƒ±r (CSV -> chunks -> embed -> qdrant)\n",
      "2) ƒ∞nteraktif arama\n",
      "3) Koleksiyon bilgilerini g√∂ster\n",
      "4) √áƒ±kƒ±≈ü\n",
      "\n",
      "üîé ƒ∞nteraktif arama ba≈ülatƒ±ldƒ±\n",
      "\n",
      "1) Basit arama\n",
      "2) Filtreli arama\n",
      "3) Ana men√º\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vekt√∂r uzunlu1024\n",
      "üîç Query vector boyutu: 512 (hedef: 512)\n",
      "üìä 5 sonu√ß bulundu\n",
      "\n",
      "üìã 5 sonu√ß:\n",
      "\n",
      "1. Skor: 0.8482\n",
      "   Esas No: 2022/3281 E. | Karar No: 2024/117 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   Metin: maddesi, ihtiyati tedbir kararƒ±nƒ±n haksƒ±z olduƒüunun belirlenmesi halinde tedbir kararƒ± y√ºz√ºnden uƒüranƒ±lan zararƒ±n tazminini d√ºzenlediƒüini, ihtiyati tedbir kararƒ±nƒ± icra ettiren tarafƒ±n yasal s√ºrede dava a√ßmamasƒ± halinde ihtiyati tedbirin haksƒ±z konulduƒüunun kabul√º gerektiƒüi, kaldƒ± ki s√ºresinde dava ...\n",
      "------------------------------------------------------------\n",
      "\n",
      "2. Skor: 0.8394\n",
      "   Esas No: 2022/3281 E. | Karar No: 2024/117 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   Metin: 3. Deƒüerlendirme Mahkemece, tazminat davalƒ±sƒ±nƒ±n √∂demekle y√ºk√ºml√º olduƒüu miktarƒ±n uyulmasƒ±na karar verilen Yargƒ±tay ilamƒ±nda da belirtildiƒüi √ºzer ihtiyati tedbir kararƒ±nƒ±n icra edildiƒüi tarih ile ihtiyati tedbirin kalktƒ±ƒüƒ± ya da kalkmƒ±≈ü sayƒ±ldƒ±ƒüƒ± tarih arasƒ±ndaki zarar olduƒüu, ihtiyati tedbir kararƒ±...\n",
      "------------------------------------------------------------\n",
      "\n",
      "3. Skor: 0.8185\n",
      "   Esas No: 2022/3281 E. | Karar No: 2024/117 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   Metin: maddesi h√ºkm√ºne aykƒ±rƒ± olarak ihtiyati tedbire ili≈ükin karar tarihinden itibaren 10 g√ºn i√ßinde dava a√ßƒ±lmamƒ±≈ü olduƒüu, haksƒ±z ihtiyati tedbirden dolayƒ± olan sorumluluƒüun kusursuz sorumluluk olduƒüu, yani, haksƒ±z ihtiyati tedbir koydurtmu≈ü olan tarafƒ±n, bundan doƒüan maddi zararla sorumlu tutulabilmesi ...\n",
      "------------------------------------------------------------\n",
      "\n",
      "4. Skor: 0.8173\n",
      "   Esas No: 2022/3281 E. | Karar No: 2024/117 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   Metin: maddesindeki on g√ºnl√ºk s√ºre i√ßerisinde esas hakkƒ±nda dava a√ßmazsa, ihtiyati tedbirin haksƒ±z konulmu≈ü sayƒ±lacaƒüƒ±, haksƒ±z ihtiyati tedbirden dolayƒ± tazminat davasƒ± a√ßan davacƒ±nƒ±n √∂denmesini istediƒüi zararƒ± ile haksƒ±z ihtiyati tedbir arasƒ±nda uygun illiyet (nedensellik) baƒüƒ± (sebep sonu√ß ili≈ükisi) bulu...\n",
      "------------------------------------------------------------\n",
      "\n",
      "5. Skor: 0.8151\n",
      "   Esas No: 2022/3281 E. | Karar No: 2024/117 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   Metin: Hukuk Dairesinin 04.06.2013 tarihli ve 2013/2984 Esas, 2013/3773 Karar sayƒ±lƒ± kararƒ±yla dava tarihinde y√ºr√ºrl√ºkte olan 1086 sayƒ±lƒ± HUMK'un 109. maddesinin ''ƒ∞htiyati tedbir kararƒ± dava ikamesinden evvel verilmi≈ü ise tatbik edilmi≈ü olsun olmasƒ±n kararƒ±n verildiƒüi tarihten itibaren on g√ºn zarfƒ±nda esa...\n",
      "------------------------------------------------------------\n",
      "\n",
      "1) Basit arama\n",
      "2) Filtreli arama\n",
      "3) Ana men√º\n",
      "vekt√∂r uzunlu1024\n",
      "üîç Query vector boyutu: 512 (hedef: 512)\n",
      "üìä 5 sonu√ß bulundu\n",
      "\n",
      "üìã 5 sonu√ß:\n",
      "\n",
      "1. Skor: 0.8039\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: B√∂lge Adliye Mahkemesinin yukarƒ±da belirtilen kararƒ±na kar≈üƒ± s√ºresi i√ßinde davalƒ± ... vekili temyiz isteminde bulunmu≈ütur. 2. Dairemizin 17.02.2022 tarihli ve 2021/2532 Esas, 2022/901 Karar sayƒ±lƒ± ilamƒ±yla; \"Mahkemece davalƒ± ... hakkƒ±ndaki tapu iptali ve tescil kararƒ± davalƒ± y√ºklenici ≈üirketin arsa ...\n",
      "------------------------------------------------------------\n",
      "\n",
      "2. Skor: 0.8025\n",
      "   Esas No: 2022/3281 E. | Karar No: 2024/117 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 30.12.2011,26.06.2009,25.12.2009,04.01.2010,05.01.2010,12.01.2010,04.06.2013,25.12.2009,31.12.2009,04.01.2010,05.01.2010,08.01.2010,13.01.2010,05.01.2010,14.01.2010,05.01.2010,14.01.2010,11.01.2024\n",
      "   Metin: maddesindeki on g√ºnl√ºk s√ºre i√ßerisinde esas hakkƒ±nda dava a√ßmazsa, ihtiyati tedbirin haksƒ±z konulmu≈ü sayƒ±lacaƒüƒ±, haksƒ±z ihtiyati tedbirden dolayƒ± tazminat davasƒ± a√ßan davacƒ±nƒ±n √∂denmesini istediƒüi zararƒ± ile haksƒ±z ihtiyati tedbir arasƒ±nda uygun illiyet (nedensellik) baƒüƒ± (sebep sonu√ß ili≈ükisi) bulu...\n",
      "------------------------------------------------------------\n",
      "\n",
      "3. Skor: 0.7978\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: ki≈üilere devretse bile 3. ki≈üi ve daha sonraki devralanlarƒ±n iyiniyet savunmasƒ±nda bulunmasƒ±nƒ±n m√ºmk√ºn olmadƒ±ƒüƒ±nƒ±, davalƒ± ...‚Äôƒ±n y√ºkleniciye kat kar≈üƒ±lƒ±ƒüƒ± in≈üaat s√∂zle≈ümesi gereƒüi avans olarak verilmi≈ü arsa √ºzerine yapƒ±lmƒ±≈ü binadan baƒüƒ±msƒ±z b√∂l√ºm edinmeyi ama√ßladƒ±ƒüƒ±nƒ±, bunun i√ßin de diƒüer davalƒ± ......\n",
      "------------------------------------------------------------\n",
      "\n",
      "4. Skor: 0.7957\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: ki≈üi olan diƒüer davalƒ±nƒ±n m√ºlkiyet hakkƒ±nƒ±n doƒümadƒ±ƒüƒ±nƒ±, yapƒ±lan satƒ±≈ü ve devrin sebepten yoksun hale geldiƒüini ve yolsuz tescil durumuna d√º≈üt√ºƒü√ºn√º, buna g√∂re de davalƒ±larƒ±n iyi niyet iddiasƒ±nda bulunamayacaƒüƒ±nƒ± belirterek 12 no.lu dairenin davalƒ± ... adƒ±na olan tapu kaydƒ±nƒ±n iptali ile davacƒ± adƒ±na...\n",
      "------------------------------------------------------------\n",
      "\n",
      "5. Skor: 0.7903\n",
      "   Esas No: 2022/3993 E. | Karar No: 2024/775 K.\n",
      "   Daire: 6.HukukDairesisi | Tarih: 04.02.2011,07.02.2011,15.07.2012,22.10.2014,16.11.2017,22.09.2020,02.12.2020,17.02.2022,15.07.2012,16.11.2017,12.07.2018,12.07.2018,08.06.2022,28.03.2024\n",
      "   Metin: maddelerinin koruyuculuƒüundan yararlanmasƒ±nƒ±n s√∂z konusu olamayacaƒüƒ±nƒ±, ilk derece mahkemesinin davanƒ±n tahkikatƒ± esnasƒ±nda Yargƒ±tay'ƒ±n baskƒ±n g√∂r√º≈ü√º etrafƒ±nda hareket ederek, arsa sahibine vaat ettiƒüi edimi ifa etmeyen y√ºklenicinin tapudaki kazanƒ±mlarƒ±nƒ±n korunmayacaƒüƒ± d√º≈ü√ºncesiyle arsa sahibine va...\n",
      "------------------------------------------------------------\n",
      "\n",
      "1) Basit arama\n",
      "2) Filtreli arama\n",
      "3) Ana men√º\n",
      "\n",
      "============================================================\n",
      "üèõÔ∏è YARGITAY BGE-M3 SEMANTƒ∞K Sƒ∞STEM\n",
      "============================================================\n",
      "1) Tam pipeline √ßalƒ±≈ütƒ±r (CSV -> chunks -> embed -> qdrant)\n",
      "2) ƒ∞nteraktif arama\n",
      "3) Koleksiyon bilgilerini g√∂ster\n",
      "4) √áƒ±kƒ±≈ü\n",
      "üëã G√∂r√º≈ü√ºr√ºz\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "# SemChunk + BGE-M3 + Qdrant Entegrasyon (Normalize edilmi≈ü, reducer uyumlu, query_points kullanƒ±yor)\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import semchunk\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n",
    "import uuid\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "print(load_dotenv(\"/home/yapayzeka/ahsen_bulbul/qdrant/.env\"))\n",
    "\n",
    "# -------------------------\n",
    "# Helper: normalize tensor rows (L2)\n",
    "# -------------------------\n",
    "def l2_normalize_tensor(t: torch.Tensor, eps: float = 1e-10) -> torch.Tensor:\n",
    "    # t: (N, D)\n",
    "    norm = torch.norm(t, dim=1, keepdim=True).clamp(min=eps)\n",
    "    return t / norm\n",
    "\n",
    "# Embed reducer (1024 -> 512)\n",
    "class EmbedReducer(nn.Module):\n",
    "    def __init__(self, input_dim: int = 1024, output_dim: int = 512):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(x)\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    BGE_MODEL_NAME: str = \"BAAI/bge-m3\"\n",
    "    USE_FP16: bool = True\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    TOKEN_SIZE: int = 512\n",
    "    ENCODING_NAME: str = \"cl100k_base\"\n",
    "    QDRANT_URL: str = \"http://localhost:6333\"\n",
    "    COLLECTION_NAME: str = \"yargitay_bge_m3_chunks\"\n",
    "    EMBEDDING_DIM: int = 512\n",
    "    CSV_FILE: str = \"/home/yapayzeka/ahsen_bulbul/data/cleaned10chunk.csv\"\n",
    "    BATCH_SIZE: int = 100\n",
    "    DB_BATCH: int = 256\n",
    "\n",
    "# -------------------------\n",
    "# Processor\n",
    "# -------------------------\n",
    "class YargitaySemanticProcessor:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "\n",
    "        # Encoding & chunker\n",
    "        self.encoding = tiktoken.get_encoding(config.ENCODING_NAME)\n",
    "        self.chunker = semchunk.chunkerify(self.encoding, config.TOKEN_SIZE)\n",
    "\n",
    "        # Model & reducer\n",
    "        print(f\"üîÆ BGE-M3 y√ºkleniyor: {config.BGE_MODEL_NAME} (device={config.DEVICE})\")\n",
    "        self.bge_model = BGEM3FlagModel(config.BGE_MODEL_NAME, use_fp16=config.USE_FP16, device=config.DEVICE)\n",
    "        self.reducer = EmbedReducer(input_dim=1024, output_dim=self.config.EMBEDDING_DIM).to(config.DEVICE)\n",
    "        reducer_path = \"/home/yapayzeka/ahsen_bulbul/reducer_weights.pt\"\n",
    "        if os.path.exists(reducer_path):\n",
    "            self.reducer.load_state_dict(torch.load(reducer_path, map_location=config.DEVICE))\n",
    "            self.reducer.eval()\n",
    "            print(\"‚ôªÔ∏è Reducer aƒüƒ±rlƒ±klarƒ± y√ºklendi\")\n",
    "        else:\n",
    "            self.reducer.eval()\n",
    "            print(\"‚ö†Ô∏è Reducer aƒüƒ±rlƒ±klarƒ± bulunamadƒ±, rastgele ba≈ülatƒ±ldƒ±\")\n",
    "        # Qdrant\n",
    "        self.qdrant_client = QdrantClient(url=config.QDRANT_URL)\n",
    "\n",
    "        device_name = torch.cuda.get_device_name() if torch.cuda.is_available() else \"CPU\"\n",
    "        print(f\"‚úÖ Hazƒ±r - Cihaz: {device_name}\")\n",
    "\n",
    "    # Test connection & print dense dim\n",
    "    def test_bge_connection(self):\n",
    "        try:\n",
    "            test_text = [\"Yargƒ±tay 6. Hukuk Dairesi'nin ihtiyati tedbir kararƒ±\"]\n",
    "            emb_res = self.bge_model.encode(test_text)\n",
    "            dense = emb_res['dense_vecs'][0]\n",
    "            print(f\"‚úÖ BGE-M3 test ba≈üarƒ±lƒ± - Dense embedding boyutu: {len(dense)}\")\n",
    "            print(f\"üîç Sparse embedding mevcut: {'colbert_vecs' in emb_res}\")\n",
    "            return len(dense)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå BGE-M3 baƒülantƒ± hatasƒ±: {e}\")\n",
    "            return None\n",
    "\n",
    "    def create_qdrant_collection(self, recreate: bool = False):\n",
    "        collection_name = self.config.COLLECTION_NAME\n",
    "        if recreate:\n",
    "            try:\n",
    "                self.qdrant_client.delete_collection(collection_name)\n",
    "                print(f\"üóëÔ∏è Eski koleksiyon silindi: {collection_name}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            existing = [c.name for c in self.qdrant_client.get_collections().collections]\n",
    "            if collection_name not in existing:\n",
    "                self.qdrant_client.create_collection(\n",
    "                    collection_name=collection_name,\n",
    "                    vectors_config=VectorParams(size=self.config.EMBEDDING_DIM, distance=Distance.COSINE)\n",
    "                )\n",
    "                print(f\"‚úÖ Koleksiyon olu≈üturuldu: {collection_name} (dim={self.config.EMBEDDING_DIM})\")\n",
    "            else:\n",
    "                print(f\"‚ÑπÔ∏è Koleksiyon zaten var: {collection_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Koleksiyon olu≈üturma hatasƒ±: {e}\")\n",
    "            raise\n",
    "\n",
    "    def semantic_chunk_text(self, text: str, metadata: dict = None) -> List[Dict]:\n",
    "        if not text or not text.strip():\n",
    "            return []\n",
    "        try:\n",
    "            chunks = self.chunker(text)\n",
    "            result = []\n",
    "            for i, c in enumerate(chunks):\n",
    "                if c.strip():\n",
    "                    cd = {\n",
    "                        'chunk_id': i,\n",
    "                        'text': c.strip(),\n",
    "                        'token_count': len(self.encoding.encode(c)),\n",
    "                        'char_count': len(c)\n",
    "                    }\n",
    "                    if metadata:\n",
    "                        cd.update(metadata)\n",
    "                    result.append(cd)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Chunking hatasƒ±: {e}\")\n",
    "            return []\n",
    "\n",
    "    def create_embeddings_bge(self, texts: List[str], batch_size: int = None) -> List[List[float]]:\n",
    "        batch_size = batch_size or self.config.BATCH_SIZE\n",
    "        all_embeddings: List[List[float]] = []\n",
    "        total = len(texts)\n",
    "        print(f\"üîÆ BGE-M3 ile {total} metin i≈üleniyor (batch_size={batch_size})...\")\n",
    "\n",
    "        for i in range(0, total, batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            try:\n",
    "                # 1) embed (BGE-M3) -> dense (1024)\n",
    "                emb_res = self.bge_model.encode(batch_texts)\n",
    "                if isinstance(emb_res, dict) and 'dense_vecs' in emb_res:\n",
    "                    dense = emb_res['dense_vecs']\n",
    "                else:\n",
    "                    dense = emb_res\n",
    "\n",
    "                # 2) to tensor, device\n",
    "                if not isinstance(dense, torch.Tensor):\n",
    "                    dense_t = torch.tensor(dense, dtype=torch.float32, device=self.config.DEVICE)\n",
    "                else:\n",
    "                    dense_t = dense.to(self.config.DEVICE)\n",
    "\n",
    "                # 3) reducer -> 512\n",
    "                with torch.no_grad():\n",
    "                    reduced = self.reducer(dense_t)\n",
    "\n",
    "                # 4) normalize L2 (important for cosine)\n",
    "                reduced = l2_normalize_tensor(reduced)\n",
    "\n",
    "                # 5) append as python lists (cpu)\n",
    "                all_embeddings.extend([v.cpu().tolist() for v in reduced])\n",
    "\n",
    "                print(f\"  üìä Batch i≈ülendi: {i + len(batch_texts)}/{total}\")\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå BGE-M3 Embedding hatasƒ± (batch {i//batch_size + 1}): {e}\")\n",
    "                # fallback zero vectors\n",
    "                all_embeddings.extend([[0.0] * self.config.EMBEDDING_DIM for _ in batch_texts])\n",
    "\n",
    "        return all_embeddings\n",
    "\n",
    "    def process_csv_file(self, csv_path: str) -> List[Dict]:\n",
    "        print(f\"üìÑ CSV okunuyor: {csv_path}\")\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            print(f\"üìä {len(df)} satƒ±r y√ºklendi\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå CSV okuma hatasƒ±: {e}\")\n",
    "            return []\n",
    "\n",
    "        text_column = next((c for c in ['rawText', 'chunk_text', 'text', 'content', 'metin'] if c in df.columns), None)\n",
    "        if not text_column:\n",
    "            print(\"‚ùå Ana metin s√ºtunu bulunamadƒ±\")\n",
    "            return []\n",
    "\n",
    "        all_chunks = []\n",
    "        for idx, row in df.iterrows():\n",
    "            text = row.get(text_column, '')\n",
    "            if not text or pd.isna(text):\n",
    "                continue\n",
    "            meta = {\n",
    "                'original_index': idx,\n",
    "                'esas_no': row.get('esasNo', ''),\n",
    "                'karar_no': row.get('kararNo', ''),\n",
    "                'daire': row.get('location', ''),\n",
    "                'tarih': row.get('extractedDates', ''),\n",
    "                'document_id': row.get('_id', ''),\n",
    "            }\n",
    "            chunks = self.semantic_chunk_text(str(text), meta)\n",
    "            all_chunks.extend(chunks)\n",
    "            if (idx + 1) % 5 == 0:\n",
    "                print(f\"  ‚úÖ ƒ∞≈ülenen satƒ±r: {idx + 1}/{len(df)} (Toplam chunk: {len(all_chunks)})\")\n",
    "\n",
    "        print(f\"üß© Toplam {len(all_chunks)} chunk olu≈üturuldu\")\n",
    "        return all_chunks\n",
    "\n",
    "    def upload_to_qdrant(self, chunks: List[Dict]):\n",
    "        if not chunks:\n",
    "            print(\"‚ùå Y√ºklenecek chunk yok\")\n",
    "            return\n",
    "\n",
    "        print(f\"üöÄ {len(chunks)} chunk Qdrant'a y√ºkleniyor...\")\n",
    "        texts = [c['text'] for c in chunks]\n",
    "        embeddings = self.create_embeddings_bge(texts)\n",
    "\n",
    "        if len(embeddings) != len(chunks):\n",
    "            print(f\"‚ùå Embedding sayƒ±sƒ± uyumsuz: {len(embeddings)} vs {len(chunks)}\")\n",
    "            return\n",
    "\n",
    "        points = []\n",
    "        for chunk, emb in zip(chunks, embeddings):\n",
    "            points.append(PointStruct(id=str(uuid.uuid4()), vector=emb, payload=chunk))\n",
    "\n",
    "        batch = self.config.DB_BATCH\n",
    "        for i in range(0, len(points), batch):\n",
    "            try:\n",
    "                self.qdrant_client.upsert(collection_name=self.config.COLLECTION_NAME, points=points[i:i+batch])\n",
    "                print(f\"  ‚úÖ Batch y√ºklendi: {min(i+batch, len(points))}/{len(points)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Batch y√ºkleme hatasƒ±: {e}\")\n",
    "\n",
    "        print(\"üéâ Y√ºkleme tamamlandƒ±!\")\n",
    "\n",
    "    # ---------- SEARCH (query_points + reducer + normalize) ----------\n",
    "    def search_semantic(self, query: str, limit: int = 10, score_threshold: float = None) -> List[Dict]:\n",
    "        try:\n",
    "            emb_res = self.bge_model.encode([query])\n",
    "            q_dense = emb_res['dense_vecs'] if isinstance(emb_res, dict) and 'dense_vecs' in emb_res else emb_res\n",
    "            print(f\"vekt√∂r uzunlu{len(q_dense[0])}\")\n",
    "            # if not isinstance(q_dense, torch.Tensor):\n",
    "            #     q_t = torch.tensor(q_dense, dtype=torch.float32, device=self.config.DEVICE)\n",
    "            # else:\n",
    "            #     q_t = q_dense.to(self.config.DEVICE)\n",
    "\n",
    "            # with torch.no_grad():\n",
    "            #     reduced_q = self.reducer(q_t)\n",
    "            #     reduced_q = l2_normalize_tensor(reduced_q)\n",
    "\n",
    "            # query_vector = reduced_q[0].cpu().tolist()\n",
    "            # print(f\"üîç Query vector boyutu: {len(query_vector)} (hedef: {self.config.EMBEDDING_DIM})\")\n",
    "\n",
    "            #use query_points (recommended)\n",
    "            qr = self.qdrant_client.query_points(\n",
    "                collection_name=self.config.COLLECTION_NAME,\n",
    "                #query=query_vector,\n",
    "                query=q_dense[0][:512],\n",
    "                limit=limit,\n",
    "                score_threshold=score_threshold\n",
    "            )\n",
    "\n",
    "            results = [{'score': p.score, 'payload': p.payload} for p in qr.points]\n",
    "            print(f\"üìä {len(results)} sonu√ß bulundu\")\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Arama hatasƒ±: {e}\")\n",
    "            return []\n",
    "\n",
    "    def advanced_search_with_filters(self, query: str, filters: Dict = None, limit: int = 10, score_threshold: float = None) -> List[Dict]:\n",
    "        try:\n",
    "            # prepare reduced + normalized query vector same as above\n",
    "            emb_res = self.bge_model.encode([query])\n",
    "            q_dense = emb_res['dense_vecs'] if isinstance(emb_res, dict) and 'dense_vecs' in emb_res else emb_res\n",
    "            if not isinstance(q_dense, torch.Tensor):\n",
    "                q_t = torch.tensor(q_dense, dtype=torch.float32, device=self.config.DEVICE)\n",
    "            else:\n",
    "                q_t = q_dense.to(self.config.DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                reduced_q = self.reducer(q_t)\n",
    "                reduced_q = l2_normalize_tensor(reduced_q)\n",
    "\n",
    "            query_vector = reduced_q[0].cpu().tolist()\n",
    "\n",
    "            query_filter = None\n",
    "            if filters:\n",
    "                from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "                conditions = [FieldCondition(key=k, match=MatchValue(value=v)) for k, v in filters.items()]\n",
    "                query_filter = Filter(must=conditions)\n",
    "\n",
    "            qr = self.qdrant_client.query_points(\n",
    "                collection_name=self.config.COLLECTION_NAME,\n",
    "                query=query_vector,\n",
    "                query_filter=query_filter,\n",
    "                limit=limit,\n",
    "                score_threshold=score_threshold\n",
    "            )\n",
    "\n",
    "            results = [{'score': p.score, 'payload': p.payload} for p in qr.points]\n",
    "            print(f\"üìä {len(results)} filtreli sonu√ß bulundu\")\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Filtreli arama hatasƒ±: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_collection_info(self) -> dict:\n",
    "        try:\n",
    "            info = self.qdrant_client.get_collection(self.config.COLLECTION_NAME)\n",
    "            return {\n",
    "                \"collection_name\": self.config.COLLECTION_NAME,\n",
    "                \"points_count\": info.points_count,\n",
    "                \"vectors_count\": info.vectors_count,\n",
    "                \"status\": info.status,\n",
    "                \"embedding_model\": \"BGE-M3\",\n",
    "                \"embedding_dim\": self.config.EMBEDDING_DIM\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "# -------------------------\n",
    "# Pipeline + main\n",
    "# -------------------------\n",
    "class YargitayPipeline:\n",
    "    def __init__(self, config: Config):\n",
    "        self.processor = YargitaySemanticProcessor(config)\n",
    "        self.config = config\n",
    "\n",
    "    def full_pipeline(self, csv_path: str = None):\n",
    "        csv_path = csv_path or self.config.CSV_FILE\n",
    "        print(\"üöÄ Full pipeline ba≈ülƒ±yor\")\n",
    "        emb_dim = self.processor.test_bge_connection()\n",
    "        if not emb_dim:\n",
    "            return False\n",
    "        # recreate collection to ensure clean 512-dim index\n",
    "        self.processor.create_qdrant_collection(recreate=True)\n",
    "        chunks = self.processor.process_csv_file(csv_path)\n",
    "        if not chunks:\n",
    "            print(\"‚ùå Chunk bulunamadƒ±\")\n",
    "            return False\n",
    "        self.processor.upload_to_qdrant(chunks)\n",
    "        info = self.processor.get_collection_info()\n",
    "        print(\"\\nüìä Koleksiyon Bilgileri:\")\n",
    "        print(json.dumps(info, indent=2, ensure_ascii=False))\n",
    "        # Reducer aƒüƒ±rlƒ±klarƒ±nƒ± kaydet\n",
    "        torch.save(self.processor.reducer.state_dict(), \"/home/yapayzeka/ahsen_bulbul/reducer_weights.pt\")\n",
    "        print(\"üíæ Reducer aƒüƒ±rlƒ±klarƒ± kaydedildi\")\n",
    "        return True\n",
    "\n",
    "    def interactive_search(self):\n",
    "        print(\"\\nüîé ƒ∞nteraktif arama ba≈ülatƒ±ldƒ±\")\n",
    "        while True:\n",
    "            print(\"\\n1) Basit arama\\n2) Filtreli arama\\n3) Ana men√º\")\n",
    "            ch = input(\"Se√ßiminiz (1-3): \").strip()\n",
    "            if ch == \"3\":\n",
    "                break\n",
    "            if ch not in {\"1\", \"2\"}:\n",
    "                print(\"‚ùå Ge√ßersiz se√ßim\")\n",
    "                continue\n",
    "            q = input(\"üîç Arama metni (√ßƒ±kmak i√ßin 'q'): \").strip()\n",
    "            if q.lower() in {'q', 'quit', 'exit'}:\n",
    "                break\n",
    "            if not q:\n",
    "                continue\n",
    "            try:\n",
    "                limit = int(input(\"Ka√ß sonu√ß? (default 5): \") or 5)\n",
    "            except:\n",
    "                limit = 5\n",
    "\n",
    "            if ch == \"1\":\n",
    "                # try with low threshold first for debugging\n",
    "                results = self.processor.search_semantic(q, limit=limit, score_threshold=None)\n",
    "            else:\n",
    "                daire = input(\"Daire filtresi (√∂rn: '6.HukukDairesi', bo≈ü = none): \").strip()\n",
    "                filters = {'daire': daire} if daire else None\n",
    "                results = self.processor.advanced_search_with_filters(q, filters=filters, limit=limit, score_threshold=None)\n",
    "\n",
    "            if not results:\n",
    "                print(\"‚ùå Sonu√ß bulunamadƒ±\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nüìã {len(results)} sonu√ß:\")\n",
    "            for i, r in enumerate(results, 1):\n",
    "                p = r['payload']\n",
    "                print(f\"\\n{i}. Skor: {r['score']:.4f}\")\n",
    "                print(f\"   Esas No: {p.get('esas_no','N/A')} | Karar No: {p.get('karar_no','N/A')}\")\n",
    "                print(f\"   Daire: {p.get('daire','N/A')} | Tarih: {p.get('tarih','N/A')}\")\n",
    "                text_preview = (p.get('text','')[:300] + '...') if len(p.get('text','')) > 300 else p.get('text','')\n",
    "                print(f\"   Metin: {text_preview}\")\n",
    "                print(\"-\"*60)\n",
    "\n",
    "def main():\n",
    "    config = Config(\n",
    "        CSV_FILE=\"/home/yapayzeka/ahsen_bulbul/data/cleaned10chunk.csv\",\n",
    "        TOKEN_SIZE=512,\n",
    "        QDRANT_URL=\"http://localhost:6333\",\n",
    "        COLLECTION_NAME=\"bge_test_chunks\",\n",
    "        EMBEDDING_DIM=512,\n",
    "        BATCH_SIZE=100\n",
    "    )\n",
    "\n",
    "    pipeline = YargitayPipeline(config)\n",
    "\n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üèõÔ∏è YARGITAY BGE-M3 SEMANTƒ∞K Sƒ∞STEM\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"1) Tam pipeline √ßalƒ±≈ütƒ±r (CSV -> chunks -> embed -> qdrant)\")\n",
    "        print(\"2) ƒ∞nteraktif arama\")\n",
    "        print(\"3) Koleksiyon bilgilerini g√∂ster\")\n",
    "        print(\"4) √áƒ±kƒ±≈ü\")\n",
    "        choice = input(\"Se√ßiminiz (1-4): \").strip()\n",
    "        if choice == \"1\":\n",
    "            csv_path = input(f\"CSV yolu (enter ile default: {config.CSV_FILE}): \").strip() or config.CSV_FILE\n",
    "            ok = pipeline.full_pipeline(csv_path)\n",
    "            print(\"‚úÖ Tamamlandƒ±\" if ok else \"‚ùå Hata √ßƒ±ktƒ±\")\n",
    "        elif choice == \"2\":\n",
    "            pipeline.interactive_search()\n",
    "        elif choice == \"3\":\n",
    "            info = pipeline.processor.get_collection_info()\n",
    "            print(json.dumps(info, indent=2, ensure_ascii=False))\n",
    "        elif choice == \"4\":\n",
    "            print(\"üëã G√∂r√º≈ü√ºr√ºz\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"‚ùå Ge√ßersiz se√ßim\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        from FlagEmbedding import BGEM3FlagModel\n",
    "        print(\"‚úÖ FlagEmbedding y√ºkl√º\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå FlagEmbedding bulunamadƒ± ‚Äî pip install FlagEmbedding\")\n",
    "        raise SystemExit(1)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahsen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
