{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "import semchunk\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct, HnswConfigDiff\n",
    "from qdrant_client. models import  Prefetch, FusionQuery, Fusion, SparseVector\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n",
    "import uuid\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import os\n",
    "from qdrant_client import models\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import json\n",
    "from qdrant_client.models import ScoredPoint\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client.http.models import NamedVector, NamedSparseVector, SparseVector, SearchRequest\n",
    "from fastembed import SparseTextEmbedding, SparseEmbedding\n",
    "from config import Config\n",
    "from config import Models, model\n",
    "from typing import List, Dict\n",
    "print(load_dotenv(\"/home/ahsen/Masa√ºst√º/stajProjesi/2025summerInternshipProject/qdrant/.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qdrant_client\n",
      "['AbortReshardingOperation', 'AbortShardTransfer', 'AbortTransferOperation', 'AbsExpression', 'AliasDescription', 'AliasOperations', 'Any', 'AnyVariants', 'AppBuildTelemetry', 'AppFeaturesTelemetry']\n",
      "<class 'qdrant_client.http.models.models.VersionInfo'>\n"
     ]
    }
   ],
   "source": [
    "import qdrant_client\n",
    "import qdrant_client.models as qm\n",
    "print(qdrant_client.__name__)\n",
    "# print(qdrant_client.__version__)\n",
    "print(dir(qm)[:10])\n",
    "print(qdrant_client.models.VersionInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    \n",
    "    def __init__(self, selected_model: str, runtime_config: Config):\n",
    "        self.selected_model = selected_model\n",
    "        self.runtime_config = runtime_config\n",
    "        self.model_config = getattr(model, str(selected_model))  # config.py‚Äôdeki model nesnesi\n",
    "        self.model = None\n",
    "        self.vectorizer = None\n",
    "\n",
    "        \n",
    "    def load_model(self):\n",
    "        model_name = self.model_config.model_name\n",
    "        model_type = self.model_config.model_type\n",
    "        print(f\"üîÆ Model y√ºkleniyor: {model_name} ({model_type})\")\n",
    "\n",
    "        if model_type == \"bge\":\n",
    "            self.model = BGEM3FlagModel(\n",
    "                model_name,\n",
    "                use_fp16=self.model_config.USE_FP16,\n",
    "                device=self.model_config.DEVICE\n",
    "            )\n",
    "        elif model_type == \"sentence_transformer\":\n",
    "            self.model = SentenceTransformer(model_name, device=self.model_config.DEVICE)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Desteklenmeyen model tipi: {model_type}\")\n",
    "\n",
    "        print(f\"‚úÖ Model y√ºklendi: {model_name}\")\n",
    "        return True\n",
    "\n",
    "    # def encode_texts(self, texts: List[str]) -> Tuple[List[List[float]], List[Dict]]:\n",
    "    #     # Dense embedding\n",
    "    #     dense_embeddings = self.model.encode(texts, convert_to_numpy=True).tolist()\n",
    "\n",
    "    #     # Sparse embedding\n",
    "    #     model_sparse = SparseTextEmbedding(model_name=self.runtime_config.SPARSE_MODEL)\n",
    "    #     sparse_embeddings_raw = list(model_sparse.embed(texts, batch_size=100))  # liste\n",
    "\n",
    "    #     sparse_embeddings = []\n",
    "    #     for s in sparse_embeddings_raw:\n",
    "    #         sparse_embeddings.append({\n",
    "    #             \"indices\": s.indices.tolist(),\n",
    "    #             \"values\": s.values.tolist()\n",
    "    #         })\n",
    "\n",
    "    #     # Dense embedding boyutunu runtime config‚Äôe g√∂re ayarla\n",
    "    #     target_dim = self.runtime_config.embedding_dim\n",
    "    #     dense_clean = []\n",
    "    #     for vec in dense_embeddings:\n",
    "    #         if vec is None:\n",
    "    #             dense_clean.append([0.0] * target_dim)\n",
    "    #         elif len(vec) < target_dim:\n",
    "    #             dense_clean.append(vec + [0.0] * (target_dim - len(vec)))\n",
    "    #         else:\n",
    "    #             dense_clean.append(vec[:target_dim])\n",
    "\n",
    "    #     return dense_clean, sparse_embeddings\n",
    "    def encode_texts(model_manager, texts, target_dim=512):\n",
    "        # Dense embedding\n",
    "        dense_embeddings = model_manager.model.encode(texts, convert_to_numpy=True).tolist()\n",
    "        dense_embeddings = [d[:target_dim] for d in dense_embeddings]  # truncate 512\n",
    "        sparse_model = SparseTextEmbedding(model_name=\"Qdrant/bm25\")\n",
    "        # Sparse embedding\n",
    "        sparse_embeddings_raw = list(sparse_model.embed(texts, batch_size=100))\n",
    "        sparse_embeddings = []\n",
    "        for s in sparse_embeddings_raw:\n",
    "            sparse_embeddings.append({\n",
    "                \"indices\": s.indices.tolist(),\n",
    "                \"values\": s.values.tolist()\n",
    "            })\n",
    "\n",
    "        return dense_embeddings, sparse_embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    def get_model_info(self) -> Dict:\n",
    "        return {\n",
    "            \"model_name\": self.model_config.model_name,\n",
    "            \"model_type\": self.model_config.model_type,\n",
    "            \"embedding_dim\": self.model_config.embedding_dim,\n",
    "            \"description\": self.model_config.description,\n",
    "            \"loaded\": self.model is not None\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class YargitaySemanticProcessor:\n",
    "\n",
    "    def __init__(self, runtime_config: Config, selected_model: str):\n",
    "        self.runtime_config = runtime_config\n",
    "        self.model_manager = ModelManager(selected_model, runtime_config)\n",
    "        self.model_manager.load_model()\n",
    "        \n",
    "        self.encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        self.chunker = semchunk.chunkerify(self.encoding, runtime_config.TOKEN_SIZE)\n",
    "\n",
    "        self.qdrant_client = QdrantClient(url=runtime_config.QDRANT_URL)\n",
    "\n",
    "        model_name = self.runtime_config.SPARSE_MODEL \n",
    "        # This triggers the model download\n",
    "        self.sparse_model = SparseTextEmbedding(model_name=model_name)\n",
    "\n",
    "    def create_qdrant_collection(self, recreate: bool = True):\n",
    "        collection_name = Config.COLLECTION_NAME\n",
    "        if recreate:\n",
    "            try:\n",
    "                self.qdrant_client.delete_collection(collection_name)\n",
    "                print(f\"üóëÔ∏è Eski koleksiyon silindi: {collection_name}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            existing = [c.name for c in self.qdrant_client.get_collections().collections]\n",
    "            if collection_name not in existing:\n",
    "                # Dense + Sparse (sparse i√ßin yine 512 dim)\n",
    "                vectors_config = {\n",
    "                    \"dense_vec\": models.VectorParams(size=self.runtime_config.embedding_dim, distance=models.Distance.COSINE),\n",
    "                }\n",
    "                sparse_config = {\n",
    "                    \"sparse_vec\": models.SparseVectorParams(\n",
    "                        index=models.SparseIndexParams(on_disk=False))\n",
    "                }\n",
    "                self.qdrant_client.create_collection(\n",
    "                    collection_name=collection_name,\n",
    "                    vectors_config=vectors_config,\n",
    "                    sparse_vectors_config = sparse_config\n",
    "                )\n",
    "                print(f\"‚úÖ Koleksiyon olu≈üturuldu: {collection_name} (Dense+Sparse)\")\n",
    "            else:\n",
    "                print(f\"‚ÑπÔ∏è Koleksiyon zaten var: {collection_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Koleksiyon olu≈üturma hatasƒ±: {e}\")\n",
    "            raise\n",
    "\n",
    "    def semantic_chunk_text(self, text: str, metadata: dict = None) -> List[Dict]:\n",
    "        if not text or not text.strip():\n",
    "            return []\n",
    "        chunks = self.chunker(text)\n",
    "        result = []\n",
    "        for i, c in enumerate(chunks):\n",
    "            if c.strip():\n",
    "                cd = {\n",
    "                    'chunk_id': i,\n",
    "                    'text': c.strip(),\n",
    "                    'token_count': len(self.encoding.encode(c)),\n",
    "                    'char_count': len(c)\n",
    "                }\n",
    "                if metadata:\n",
    "                    cd.update(metadata)\n",
    "                result.append(cd)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def process_csv_file(self, csv_path: str = \"/home/ahsen/Masa√ºst√º/stajProjesi/2025summerInternshipProject/data/cleaned10chunk.csv\") -> List[Dict]:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        text_column = next((c for c in ['rawText','chunk_text','text','content','metin'] if c in df.columns), None)\n",
    "        if not text_column:\n",
    "            print(\"‚ùå Ana metin s√ºtunu bulunamadƒ±\")\n",
    "            return []\n",
    "\n",
    "        all_chunks = []\n",
    "        for idx, row in df.iterrows():\n",
    "            text = row.get(text_column, '')\n",
    "            if not text or pd.isna(text):\n",
    "                continue\n",
    "            meta = {\n",
    "                'original_index': idx,\n",
    "                'esas_no': row.get('esasNo', ''),\n",
    "                'karar_no': row.get('kararNo', ''),\n",
    "                'daire': row.get('location', ''),\n",
    "                'tarih': row.get('extractedDates', ''),\n",
    "                'document_id': row.get('_id', ''),\n",
    "            }\n",
    "            chunks = self.semantic_chunk_text(str(text), meta)\n",
    "            all_chunks.extend(chunks)\n",
    "        \n",
    "        \n",
    "        return all_chunks\n",
    "\n",
    "    def create_embeddings(self, texts: List[str], batch_size: int = None):\n",
    "        \"\"\"Dinamik model ile embedding olu≈ütur\"\"\"\n",
    "        batch_size = batch_size or self.runtime_config.BATCH_SIZE\n",
    "        \n",
    "        all_embeddings_dense, all_embeddings_sparse = [], []\n",
    "        total = len(texts)\n",
    "        print(f\"üîÆ {total} metin i≈üleniyor (model: {self.runtime_config.model_name})...\")\n",
    "\n",
    "        for i in range(0, total, batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            try:\n",
    "                dense, sparse = self.model_manager.encode_texts(batch_texts)\n",
    "                all_embeddings_dense.extend(dense)\n",
    "                all_embeddings_sparse.extend(sparse)\n",
    "                \n",
    "                print(f\"  üìä Batch i≈ülendi: {i + len(batch_texts)}/{total}\")\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Embedding hatasƒ± (batch {i//batch_size+1}): {e}\")\n",
    "                # Fallback\n",
    "                all_embeddings_dense.extend([[0.0]*self.runtime_config.embedding_dim for _ in batch_texts])\n",
    "                all_embeddings_sparse.extend([{\"indices\": [], \"values\": []} for _ in batch_texts])\n",
    "\n",
    "        return all_embeddings_dense, all_embeddings_sparse\n",
    "\n",
    "    # def upload_to_qdrant(qdrant_client, chunks, dense_embeddings, sparse_embeddings, collection_name):\n",
    "    #     points = []\n",
    "\n",
    "    #     for c, d, s in zip(chunks, dense_embeddings, sparse_embeddings):\n",
    "    #         vector_dict = {\"dense_vec\": d}\n",
    "    #         if s and len(s[\"indices\"]) > 0:\n",
    "    #             vector_dict[\"sparse_vec\"] = SparseVector(indices=s[\"indices\"], values=s[\"values\"])\n",
    "    #         points.append(PointStruct(id=str(uuid.uuid4()), vector=vector_dict, payload=c))\n",
    "\n",
    "    #     # Batch upload\n",
    "    #     batch_size = 64\n",
    "    #     for i in range(0, len(points), batch_size):\n",
    "    #         qdrant_client.upsert(collection_name=collection_name, points=points[i:i+batch_size])\n",
    "\n",
    "    #     print(f\"‚úÖ {len(points)} noktalar Qdrant'a y√ºklendi!\")\n",
    "    \n",
    "\n",
    "    def upload_to_qdrant(self, chunks: List[Dict]):\n",
    "        dense_embeddings, sparse_embeddings = self.model_manager.encode_texts([c[\"text\"] for c in chunks])\n",
    "        \n",
    "        points = []\n",
    "        for c, d, s in zip(chunks, dense_embeddings, sparse_embeddings):\n",
    "            vector_dict = {\"dense_vec\": d[:512]}\n",
    "            \n",
    "            if s is not None:\n",
    "                # s artƒ±k dict formatƒ±nda: {\"indices\": [...], \"values\": [...]}\n",
    "                indices = s.get(\"indices\", [])\n",
    "                values = s.get(\"values\", [])\n",
    "                \n",
    "                if len(indices) > 0:\n",
    "                    vector_dict[\"sparse_vec\"] = SparseVector(indices=indices, values=values)\n",
    "            \n",
    "            points.append(PointStruct(id=str(uuid.uuid4()), vector=vector_dict, payload=c))\n",
    "        \n",
    "        # batch upload\n",
    "        batch_size = self.runtime_config.BATCH_SIZE\n",
    "        for i in range(0, len(points), batch_size):\n",
    "            self.qdrant_client.upsert(\n",
    "                collection_name=Config.COLLECTION_NAME,\n",
    "                points=points[i:i+batch_size]\n",
    "            )\n",
    "        print(f\"‚úÖ {len(points)} noktalar Qdrant'a y√ºklendi!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model() -> str:\n",
    "    print(\"ü§ñ Model Se√ßimi:\")\n",
    "    for name in vars(model):\n",
    "        m = getattr(model, name)\n",
    "        print(f\"{name}: {m.description} (Dim: {m.embedding_dim})\")\n",
    "    choice = input(\"Model se√ßin (default bge_m3): \").strip() or \"bge_m3\"\n",
    "    if choice not in vars(model):\n",
    "        choice = \"bge_m3\"\n",
    "    return choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Model Se√ßimi:\n",
      "bge_m3: BGE-M3 - √áok dilli, dense+sparse embedding destekli (Dim: 1024)\n",
      "bge_large: BGE Large - Sadece dense embedding (Dim: 1024)\n",
      "multilingual_e5: E5 Multilingual Large - √áok dilli dense embedding (Dim: 1024)\n",
      "turkish_bert: Turkish BERT - T√ºrk√ße √∂zelle≈ütirilmi≈ü (Dim: 768)\n",
      "distilbert_turkish: Hƒ±zlƒ± T√ºrk√ße DistilBERT (Dim: 768)\n",
      "all_mpnet: All-MiniLM - Genel ama√ßlƒ±, hƒ±zlƒ± (Dim: 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'all_mpnet'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_model = select_model()\n",
    "selected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_mpnet <class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Config(SPARSE_MODEL='Qdrant/bm25', USE_FP16=True, DEVICE='cpu', TOKEN_SIZE=512, ENCODING_NAME='cl100k_base', QDRANT_URL='http://localhost:6333', COLLECTION_NAME='hybrid', CSV_FILE='/home/ahsen/Masa√ºst√º/stajProjesi/2025summerInternshipProject/data/cleaned10chunk.csv', BATCH_SIZE=100, DB_BATCH=256, model_name='sentence-transformers/all-mpnet-base-v2', model_type='sentence_transformer', embedding_dim=768, max_seq_length=384, description='All-MiniLM - Genel ama√ßlƒ±, hƒ±zlƒ±')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(selected_model, type(selected_model))\n",
    "selected_config = getattr(model, selected_model)\n",
    "selected_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_mpnet\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(selected_model)              \n",
    "print(hasattr(model, selected_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Model y√ºkleniyor: sentence-transformers/all-mpnet-base-v2 (sentence_transformer)\n",
      "‚úÖ Model y√ºklendi: sentence-transformers/all-mpnet-base-v2\n",
      "üóëÔ∏è Eski koleksiyon silindi: hybrid\n",
      "‚úÖ Koleksiyon olu≈üturuldu: hybrid (Dense+Sparse)\n"
     ]
    }
   ],
   "source": [
    "processor = YargitaySemanticProcessor(Config, selected_model)\n",
    "processor.create_qdrant_collection(recreate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 59 noktalar Qdrant'a y√ºklendi!\n",
      "‚úÖ Pipeline tamamlandƒ±!\n"
     ]
    }
   ],
   "source": [
    "chunks = processor.process_csv_file(Config.CSV_FILE)\n",
    "processor.upload_to_qdrant(chunks)\n",
    "print(\"‚úÖ Pipeline tamamlandƒ±!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Model y√ºkleniyor: sentence-transformers/all-mpnet-base-v2 (sentence_transformer)\n",
      "‚úÖ Model y√ºklendi: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<qdrant_client.qdrant_client.QdrantClient at 0x7fc4d8f49de0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_manager = ModelManager(selected_model, selected_config)\n",
    "model_manager.load_model()\n",
    "\n",
    "qdrant_client = QdrantClient(url=Config.QDRANT_URL)\n",
    "qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"ihtiyati tedbir taazminat nedir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_emb = model_manager.encode_texts([query])\n",
    "# dense_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_semantic(query: str, limit: int = 10, score_threshold: float = None) -> List[Dict]:\n",
    "        model_manager = ModelManager(selected_model, selected_config)\n",
    "        model_manager.load_model()\n",
    "        qdrant_client = QdrantClient(url=Config.QDRANT_URL)\n",
    "        \"\"\"Dense semantic search\"\"\"\n",
    "\n",
    "        try:\n",
    "            \n",
    "            dense_emb,sparse_emb = model_manager.encode_texts([query])\n",
    "            query_vector = dense_emb[0][:512]\n",
    "            sparse_emb=None\n",
    "            \n",
    "            qr = qdrant_client.query_points(\n",
    "                collection_name=Config.COLLECTION_NAME,\n",
    "                query=query_vector, \n",
    "                using=\"dense_vec\",\n",
    "                limit=5\n",
    "            )\n",
    "            \n",
    "\n",
    "            results = [{\"score\": p.score, \"payload\": p.payload} for p in qr.points]\n",
    "            print(f\"üìä {len(results)} sonu√ß bulundu (Dense only)\")\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Semantic search hatasƒ±: {e}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_hybrid(query: str, limit: int = 10, score_threshold: float = None) -> List[Dict]:\n",
    "    model_manager = ModelManager(selected_model, selected_config)\n",
    "    model_manager.load_model()\n",
    "    qdrant_client = QdrantClient(url=Config.QDRANT_URL)\n",
    "    \"\"\"Hybrid search (Dense + Sparse)\"\"\"\n",
    "\n",
    "    try:\n",
    "        dense_emb,sparse_emb = model_manager.encode_texts([query])\n",
    "        #query_vector = dense_emb[0][:512]\n",
    "        \n",
    "\n",
    "        s = sparse_emb[0]\n",
    "        query_sparse_vector = SparseVector(indices=s[\"indices\"], values=s[\"values\"])\n",
    "        qr=qdrant_client.query_points(\n",
    "            collection_name=Config.COLLECTION_NAME,\n",
    "            prefetch=[\n",
    "                models.Prefetch(\n",
    "                    query=query_sparse_vector,  # sparse vector\n",
    "                    using=\"sparse_vec\",\n",
    "                    limit=5,\n",
    "                ),\n",
    "                models.Prefetch(\n",
    "                    query=dense_emb[0],  # <-- dense vector\n",
    "                    using=\"dense_vec\",\n",
    "                    limit=20,\n",
    "                ),\n",
    "            ],\n",
    "            query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        )\n",
    "            \n",
    "\n",
    "            # results = []\n",
    "            # for sp in qr:  # sp: ScoredPoint\n",
    "                \n",
    "            #     results.append({\n",
    "            #         \"score\": sp.score,\n",
    "            #         \"payload\": sp.point.payload\n",
    "            #     })\n",
    "\n",
    "            \n",
    "        results = [{\"score\": p.score, \"payload\": p.payload} for p in qr.points]\n",
    "        print(f\"üìä {len(results)} sonu√ß bulundu \")\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Hybrid search hatasƒ±: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"ihtiyati tedbir tazminat \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager = ModelManager(selected_model, selected_config)\n",
    "model_manager.load_model()\n",
    "qdrant_client = QdrantClient(url=Config.QDRANT_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_emb,sparse_emb = model_manager.encode_texts([query])\n",
    "query_vector = dense_emb[0][:512]\n",
    "sparse_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search():\n",
    "    print(\"\\nüîé ƒ∞nteraktif arama ba≈ülatƒ±ldƒ±\")\n",
    "    print(processor.model_manager.get_model_info())\n",
    "    \n",
    "    while True:\n",
    "            \n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(\"üîç ARAMA SE√áENEKLERƒ∞\")\n",
    "            print(\"1-only dense\")\n",
    "            print(\"2-dense + sparse\")\n",
    "            choice = input(\"Se√ßiminiz (1/2/3, √ßƒ±kmak i√ßin q): \").strip()\n",
    "            if choice.lower() == 'q':\n",
    "                print(\"√áƒ±kƒ±lƒ±yor...\")\n",
    "                break\n",
    "            if choice not in ['1', '2', '3']:\n",
    "                print(\"Ge√ßersiz se√ßim, tekrar deneyin.\")\n",
    "                continue\n",
    "            query = input(\"Arama sorgusu girin: \").strip()\n",
    "            if not query:\n",
    "                print(\"Bo≈ü sorgu, tekrar deneyin.\")\n",
    "                continue\n",
    "            if choice == '1':\n",
    "                results = search_semantic(query, limit=10, score_threshold=0.6)\n",
    "            elif choice == '2':\n",
    "                results = search_hybrid(query, limit=10, score_threshold=0.6)\n",
    "            print(f\"\\nüìä {len(results)} sonu√ß bulundu:\")\n",
    "            \n",
    "            for idx, r in enumerate(results, 1):\n",
    "                print(f\"{idx}. Score: {r['score']:.4f}, Text: {r['payload'].get('text','')[:200]}...\")  # ilk 200 karakter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé ƒ∞nteraktif arama ba≈ülatƒ±ldƒ±\n",
      "{'model_name': 'sentence-transformers/all-mpnet-base-v2', 'model_type': 'sentence_transformer', 'embedding_dim': 768, 'description': 'All-MiniLM - Genel ama√ßlƒ±, hƒ±zlƒ±', 'loaded': True}\n",
      "\n",
      "==================================================\n",
      "üîç ARAMA SE√áENEKLERƒ∞\n",
      "1-only dense\n",
      "2-dense + sparse\n",
      "üîÆ Model y√ºkleniyor: sentence-transformers/all-mpnet-base-v2 (sentence_transformer)\n",
      "‚úÖ Model y√ºklendi: sentence-transformers/all-mpnet-base-v2\n",
      "üìä 5 sonu√ß bulundu (Dense only)\n",
      "\n",
      "üìä 5 sonu√ß bulundu:\n",
      "1. Score: 0.6367, Text: maddesi h√ºkm√ºne aykƒ±rƒ± olarak ihtiyati tedbire ili≈ükin karar tarihinden itibaren 10 g√ºn i√ßinde dava a√ßƒ±lmamƒ±≈ü olduƒüu, haksƒ±z ihtiyati tedbirden dolayƒ± olan sorumluluƒüun kusursuz sorumluluk olduƒüu, yan...\n",
      "2. Score: 0.6265, Text: maddesi \"Aksi takdirde ihtiyati tedbir bir g√ªna merasime hacet kalmaksƒ±zƒ±n kendiliƒüinden kalkar ve iktizasƒ±na g√∂re vazolunan tedbirin fiilen kaldƒ±rƒ±lmasƒ± ihtiyati tedbiri tatbik eden daire veya memurd...\n",
      "3. Score: 0.6139, Text: Belediye Ba≈ükanlƒ±ƒüƒ±na kararƒ±n infazƒ± i√ßin m√ºzekkere yazƒ±ldƒ±ƒüƒ± ve 05/01/2010 tarih saat 08:50 itibari ile ƒ∞n≈üaatƒ±n m√ºh√ºrlenmesi suretiyle kararƒ±n infaz edildiƒüi, davalƒ± HUMK'un 109.maddesinde belirtile...\n",
      "4. Score: 0.5802, Text: maddesi, ihtiyati tedbir kararƒ±nƒ±n haksƒ±z olduƒüunun belirlenmesi halinde tedbir kararƒ± y√ºz√ºnden uƒüranƒ±lan zararƒ±n tazminini d√ºzenlediƒüini, ihtiyati tedbir kararƒ±nƒ± icra ettiren tarafƒ±n yasal s√ºrede da...\n",
      "5. Score: 0.5791, Text: sayƒ±lƒ± dosyasƒ± √ºzerinden 26.06.2009 tarihinde tedbir talep edildiƒüi, yapƒ±lan ke≈üif sonucu bilirki≈üilerin raporlarƒ±nƒ± ibraz ettikleri, 25.12.2009 tarihinde 2776 Parsel √ºzerinde yapƒ±mƒ±na devam edilen in...\n",
      "\n",
      "==================================================\n",
      "üîç ARAMA SE√áENEKLERƒ∞\n",
      "1-only dense\n",
      "2-dense + sparse\n",
      "√áƒ±kƒ±lƒ±yor...\n",
      "\n",
      "üîé ƒ∞nteraktif arama ba≈ülatƒ±ldƒ±\n",
      "{'model_name': 'sentence-transformers/all-mpnet-base-v2', 'model_type': 'sentence_transformer', 'embedding_dim': 768, 'description': 'All-MiniLM - Genel ama√ßlƒ±, hƒ±zlƒ±', 'loaded': True}\n",
      "\n",
      "==================================================\n",
      "üîç ARAMA SE√áENEKLERƒ∞\n",
      "1-only dense\n",
      "2-dense + sparse\n",
      "√áƒ±kƒ±lƒ±yor...\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "search()\n",
    "print(search())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihtiyati tedbir tazminat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
